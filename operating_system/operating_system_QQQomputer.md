## 1. 운영체제의 큰 그림

### 운영체제의 의미

- **운영체제**: 프로그램들 간의 올바른 실행을 돕고, 하드웨어 자원을 프로그램에 배분하는 프로그램
- **중요성**: 하드웨어를 작동시키는 프로그램으로 컴퓨터 전체에서 가장 중요한 프로그램
- 프로그램 실행과 개발의 근간이 되므로 운영체제에 대한 이해가 필수적

### 운영체제의 종류

- **데스크탑**: Windows, macOS, Linux
- **모바일**: Android, iOS

### 운영체제의 핵심 구성요소

- **커널**: 운영체제의 핵심 부분, 자동차의 엔진이나 사람의 심장과 같은 역할
- **시스템 콜**: 응용 프로그램이 운영체제 기능을 사용하기 위한 인터페이스

### 운영체제의 핵심 기능

1. **자원 할당 및 관리**
    - CPU 관리: CPU 스케줄링
    - 메모리 관리: 가상 메모리
    - 파일/디렉터리 관리: 파일 시스템
    - 입출력장치 및 캐시 메모리 관리
2. **프로세스 및 스레드 관리**
    - 프로세스와 스레드
    - 동기화와 교착상태

### 운영체제 지도 그리기

```
- 커널
운영체제의 큰 그림 - 시스템 콜

운영체제 -
- 프로세스와 스레드
프로세스 및 스레드 관리 -
- 동기화와 교착상태
- CPU 관리: CPU 스케줄링
- 기본 개념 - 우선순위, 스케줄링 큐, 선점형과 비선점형
CPU 스케줄링 알고리즘
- 리눅스 CPU 스케줄링

자원 할당 및 관리
- 물리 주소와 논리 주소
메모리 관리: 가상 메모리 - 메모리 할당
- 페이징과 페이지 교체 알고리즘
- 파일과 디렉터리
파일/디렉터리 관리: 파일 시스템 -
파일 시스템

```

## 2. 시스템 콜과 이중 모드

### 커널 영역과 사용자 영역

- **커널 영역**: 운영체제가 적재되는 메모리 영역
- **사용자 영역**: 사용자 응용 프로그램이 적재되는 메모리 영역
- 운영체제의 기능을 제공받기 위해서는 커널 영역에 적재된 운영체제 코드를 실행해야 함

### 시스템 콜

- **의미**: 운영체제 서비스를 제공받기 위한 인터페이스
- **특징**: 소프트웨어 인터럽트를 통해 커널 모드로 전환
- **종류**:
    - **프로세스 관리**:
        - `fork()`: 새 자식 프로세스 생성
        - `exec()`: 프로세스 실행(메모리 공간을 새로운 프로그램의 내용으로 덮어씌움)
        - `exit()`: 프로세스 종료
        - `waitpid()`: 자식 프로세스가 종료할 때까지 대기
    - **파일 관리**:
        - `open()`: 파일 열기
        - `close()`: 파일 닫기
        - `read()`: 파일 읽기
        - `write()`: 파일 쓰기
    - **디렉터리 관리**:
        - `stat()`: 파일 정보 획득
        - `chdir()`: 작업 디렉터리 변경
        - `mkdir()`: 디렉터리 생성
        - `rmdir()`: 비어 있는 디렉터리 삭제
    - **파일 시스템 관리**:
        - `mount()`: 파일 시스템 마운트
        - `umount()`: 파일 시스템 마운트 해제

### 프로세스의 계층 구조

- 프로세스는 시스템 콜을 통해 또 다른 프로세스를 생성할 수 있음
- 부모 프로세스(parent process): 새 프로세스를 생성한 프로세스
- 자식 프로세스(child process): 부모 프로세스에 의해 생성된 프로세스

### 사용자 모드와 커널 모드

- **이중 모드**: CPU가 명령어를 실행하는 모드를 구분하는 것
    - CPU의 슈퍼바이저 플래그로 현재 모드 구분
- **사용자 모드**: 제한된 권한으로 실행되는 모드
    - 자원에 직접 접근 불가
    - 입출력 명령어 등 자원 접근 명령어 실행 불가
- **커널 모드**: 모든 권한을 가진 모드
    - 모든 자원에 접근 가능
    - 모든 명령어 실행 가능

### 시스템 콜 실행 과정

1. 사용자 프로그램이 시스템 콜 호출 (소프트웨어 인터럽트 발생)
2. CPU는 현재 작업을 백업하고 사용자 모드에서 커널 모드로 전환
3. 커널 영역 내 인터럽트 처리 코드 실행
4. 작업 완료 후 사용자 모드로 전환하여 사용자 프로그램 실행 재개

### 시스템 콜 예시

일반적인 프로그램은 실행 과정에서 수백 번의 시스템 콜을 호출함:

```
$ strace -c python3 test.py
hello world!
% time  seconds  usecs/call  calls  errors  syscall
20.19   0.000213      2       103           read
18.39   0.000194      1        14           getdents64
10.14   0.000107      0       111     72    openat
...

```

## 3. 프로세스와 스레드

### 프로세스의 정의와 유형

- **프로세스**: 실행 중인 프로그램
- **유형**:
    - **포그라운드 프로세스**: 사용자와 상호작용하는 프로세스
    - **백그라운드 프로세스**: 사용자가 보지 못하는 곳에서 실행되는 프로세스
    - **데몬/서비스**: 사용자와 상호작용 없이 주어진 작업만 수행하는 특별한 백그라운드 프로세스

### 프로세스 메모리 구성

- **구성**: PCB(Process Control Block)와 메모리 영역
- **코드 영역**(Code segment):
    - 실행 가능한 명령어가 저장되는 공간
    - 텍스트 영역(Text segment)이라고도 함
    - 읽기 전용(read-only) 공간
- **데이터 영역**(Data segment):
    - 프로그램이 실행되는 동안 유지할 데이터가 저장되는 공간
    - 정적 변수나 전역 변수가 저장됨
- **BSS 영역**:
    - 초기화되지 않은 정적 변수나 전역 변수가 저장되는 공간
    - 데이터 영역과 유사하지만 초깃값이 없는 데이터를 저장
- **힙 영역**(Heap segment):
    - 프로그래머가 직접 할당 가능한 저장 공간
    - 동적 할당 영역
    - 메모리 누수(memory leak) 발생 가능성
    - 가비지 컬렉션(garbage collection)으로 관리 가능
- **스택 영역**(Stack segment):
    - 일시적으로 사용할 값들이 저장되는 공간
    - 함수의 매개변수, 지역 변수, 함수 복귀 주소 등 저장
    - 동적 할당 영역
    - 스택 트레이스 형태의 함수 호출 정보 저장

### PCB와 문맥 교환

- **PCB(Process Control Block)**: 프로세스 관련 정보를 저장하는 구조체
    - PID(프로세스 식별 번호)
    - 레지스터 값(프로그램 카운터 포함)
    - 프로세스 상태
    - CPU 스케줄링 정보(우선순위)
    - 메모리 관련 정보
    - 파일 및 입출력장치 관련 정보
- **리눅스 PCB 예시**(task_struct):
    
    ```c
    struct task_struct {
        pid_t pid;            // PID
        int prio;             // 스케줄링(우선 순위) 관련 정보
        unsigned int state;   // 프로세스 상태 관련 정보
        struct mm_struct *mm; // 메모리 관련 정보
        void *stack;          // 스택 관련 정보
        struct files_struct *files; // 파일 관련 정보
    }
    
    ```
    
- **문맥 교환**(Context Switch):
    - 실행 중인 프로세스를 중단하고 다른 프로세스로 전환하는 과정
    - 현재 프로세스의 상태를 PCB에 저장하고, 다음 프로세스의 상태를 PCB에서 복원
    - 잦은 문맥 교환은 캐시 미스와 오버헤드 발생 가능성 높임

### 프로세스의 상태

- **생성 상태**(new):
    - 프로세스를 생성 중인 상태
    - 메모리에 적재되어 PCB를 할당받은 상태
- **준비 상태**(ready):
    - CPU를 할당받기 위해 기다리는 상태
    - 디스패치(dispatch): 준비 상태의 프로세스가 실행 상태로 전환되는 것
- **실행 상태**(running):
    - CPU를 할당받아 실행 중인 상태
    - 타이머 인터럽트로 인해 준비 상태로 전환 가능
    - 입출력 작업으로 인해 대기 상태로 전환 가능
- **대기 상태**(blocked):
    - 입출력 작업을 요청하거나 확보할 수 없는 자원을 요청한 경우
    - 실행이 불가능한 조건에 놓인 상태
- **종료 상태**(terminated):
    - 프로세스가 종료된 상태
    - PCB와 자원이 정리됨

### 블로킹 입출력과 논블로킹 입출력

- **블로킹 입출력**:
    - 입출력 작업이 완료될 때까지 프로세스가 대기 상태로 전환
    - 작업 완료 후 준비 상태로 전환
- **논블로킹 입출력**:
    - 입출력 작업을 요청한 후 즉시 제어권을 반환
    - 입출력 작업이 완료되기를 기다리지 않고 계속 실행

### 멀티프로세스와 멀티스레드

- **멀티프로세스**:
    - 여러 개의 프로세스가 독립적으로 실행됨
    - 자원을 공유하지 않고, 독립적인 메모리 공간 사용
    - 한 프로세스의 문제가 다른 프로세스에 영향을 적게 미침
- **스레드**:
    - 프로세스 내에서 실행되는 작업의 단위
    - 구성 요소: 스레드 ID, 프로그램 카운터, 레지스터 값, 스택
    - 같은 프로세스 내 스레드들은 코드, 데이터, 힙 영역을 공유
- **멀티스레드**:
    - 하나의 프로세스 내에서 여러 스레드가 실행됨
    - 자원 공유, 효율적 통신 가능
    - 한 스레드의 문제가 전체 프로세스에 영향을 미칠 수 있음

### 멀티스레드 프로그래밍 예제

```python
import threading
import os

def foo():
    pid = os.getpid()  # 현재 프로세스의 pid를 반환
    tid = threading.get_native_id()  # 현재 스레드의 id를 반환
    print(f"foo: PID={pid}, Thread ID={tid}")

def bar():
    pid = os.getpid()
    tid = threading.get_native_id()
    print(f"bar: PID={pid}, Thread ID={tid}")

def baz():
    pid = os.getpid()
    tid = threading.get_native_id()
    print(f"baz: PID={pid}, Thread ID={tid}")

if __name__ == "__main__":
    thread1 = threading.Thread(target=foo)  # 첫 번째 스레드 생성, 실행할 함수는 foo
    thread2 = threading.Thread(target=bar)  # 두 번째 스레드 생성, 실행할 함수는 bar
    thread3 = threading.Thread(target=baz)  # 세 번째 스레드 생성, 실행할 함수는 baz

    thread1.start()  # 첫 번째 스레드 실행
    thread2.start()  # 두 번째 스레드 실행
    thread3.start()  # 세 번째 스레드 실행

```

실행 결과:

```
foo: PID=5113, TID=2149548
bar: PID=5113, TID=2149549
baz: PID=5113, TID=2149550

```

### 스레드 조인

- **join()**: 스레드의 실행이 종료될 때까지 대기하는 메서드
- 사용 예시:
    
    ```python
    thread1.join()
    thread2.join()
    thread3.join()
    
    ```
    
- 공식 문서 설명:
    - C++: "The function returns when the thread execution has completed."
    - 파이썬: "스레드가 종료할 때까지 기다립니다."

### 프로세스 간 통신(IPC)

- **정의**: 프로세스 간에 자원을 공유하고 데이터를 주고받는 메커니즘
- **종류**:
    
    ### 공유 메모리
    
    - 프로세스 간에 공유하는 메모리 영역을 통한 통신
    - 커널의 개입 없이 통신 가능
    - 통신 속도가 빠름
    - 동기화 문제(레이스 컨디션) 발생 가능
    
    ### 메시지 전달
    
    - 커널을 통해 메시지를 주고받는 방식
    - 통신 속도는 상대적으로 느림
    - 동기화 문제가 적음
        
        ### 파이프(pipe)
        
        - 단방향 통신을 지원하는 도구
        - 양방향 통신을 위해선 두 개의 파이프 필요
        - **익명 파이프(unnamed pipe)**: 부모-자식 프로세스 간 통신에만 사용 가능
        - **지명 파이프(named pipe/FIFO)**: 관련 없는 프로세스 간에도 통신 가능
        
        ### 시그널(signal)
        
        - 프로세스에게 특정 이벤트가 발생했음을 알리는 비동기적 신호
        - 리눅스 시그널 예시:
            - SIGCHLD: 자식 프로세스 종료
            - SIGHUP: 허용하지 않은 명령어 실행
            - SIGINT: 키보드 인터럽트(Ctrl+C)
            - SIGKILL: 프로세스 강제 종료(핸들러 재정의 불가능)
            - SIGSEGV: 잘못된 메모리 접근
            - SIGTERM: 프로세스 종료(핸들러 재정의 가능)
            - SIGUSR1/SIGUSR2: 사용자 정의 시그널
        - 시그널 기본 동작: 무시, 종료, 코어 덤프 생성 후 종료
        
        ### 코어 덤프(core dump)
        
        - 비정상적으로 종료하는 경우에 생성되는 파일
        - 프로그램이 특정 시점에 작업하던 메모리 상태 기록
        - 디버깅 용도로 활용
        
        ### 소켓(socket)
        
        - 네트워크 통신을 통한 프로세스 간 통신
        - 로컬 및 원격 프로세스 간 통신 가능
        
        ### 원격 프로시저 호출(RPC)
        
        - 원격 코드를 실행하는 IPC 기술
        - 프로그래밍 언어나 플랫폼과 무관하게 통신 가능
        - 대규모 트래픽 처리 환경에서 주로 사용

## 4. 동기화와 교착상태

### 레이스 컨디션과 임계 구역

- **공유 자원**: 여러 프로세스 또는 스레드가 공유하는 자원(메모리, 파일, 전역 변수 등)
- **임계 구역**(Critical Section): 공유 자원에 접근하는 코드 중 동시에 실행하면 문제가 발생할 수 있는 부분
- **레이스 컨디션**(Race Condition): 여러 프로세스/스레드가 동시에 임계 구역을 실행하여 자원 일관성이 손상되는 상황

### 레이스 컨디션 예제

```c
#include <stdio.h>
#include <pthread.h>

int shared_data = 0;    // 공유 데이터

void* increment(void* arg) {
    int i;
    for (i = 0; i < 100000; i++) {
        shared_data++; // 공유 데이터 증가
    }
    return NULL;
}

void* decrement(void* arg) {
    int i;
    for (i = 0; i < 100000; i++) {
        shared_data--; // 공유 데이터 감소
    }
    return NULL;
}

int main() {
    pthread_t thread1, thread2;
    pthread_create(&thread1, NULL, increment, NULL);
    pthread_create(&thread2, NULL, decrement, NULL);
    pthread_join(thread1, NULL);
    pthread_join(thread2, NULL);
    printf("Final value of shared_data: %d\n", shared_data);
    return 0;
}

```

실행 결과:

```
$ ./race
Final value of shared_data: -3394
$ ./race
Final value of shared_data: -3457
$ ./race
Final value of shared_data: 1848

```

### 동기화 기법

### 뮤텍스 락(Mutex Lock)

- **목적**: 상호 배제를 보장하는 동기화 도구
- **원리**: 임계 구역 진입 전 락 획득, 작업 후 락 해제
- **acquire()**: 락 획득 함수, 다른 프로세스/스레드가 이미 획득했다면 해제될 때까지 대기
- **release()**: 락 해제 함수

### 뮤텍스 락 예제(C/C++)

```c
#include <stdio.h>
#include <pthread.h>

int shared_data = 0;    // 공유 데이터
pthread_mutex_t mutex; // 뮤텍스 선언

void* increment(void* arg) {
    int i;
    for (i = 0; i < 100000; i++) {
        pthread_mutex_lock(&mutex);    // 뮤텍스 락 획득
        shared_data++;                 // 공유 데이터 증가
        pthread_mutex_unlock(&mutex);  // 뮤텍스 락 해제
    }
    return NULL;
}

void* decrement(void* arg) {
    int i;
    for (i = 0; i < 100000; i++) {
        pthread_mutex_lock(&mutex);    // 뮤텍스 락 획득
        shared_data--;                 // 공유 데이터 감소
        pthread_mutex_unlock(&mutex);  // 뮤텍스 락 해제
    }
    return NULL;
}

int main() {
    pthread_t thread1, thread2;
    pthread_mutex_init(&mutex, NULL); // 뮤텍스 초기화
    pthread_create(&thread1, NULL, increment, NULL);
    pthread_create(&thread2, NULL, decrement, NULL);
    pthread_join(thread1, NULL);
    pthread_join(thread2, NULL);
    printf("Final value of shared_data: %d\n", shared_data);
    pthread_mutex_destroy(&mutex);     // 뮤텍스 해제
    return 0;
}

```

### 세마포(Semaphore)

- **목적**: 여러 개의 공유 자원을 관리하는 동기화 도구
- **구성 요소**:
    - 변수 S: 사용 가능한 공유 자원의 개수
    - wait() 함수: 임계 구역 진입 전 호출, S 감소
    - signal() 함수: 임계 구역 종료 후 호출, S 증가
- wait() 구현:
    
    ```
    wait() {    S--;    if (S < 0) {        sleep();    }}
    
    ```
    
- signal() 구현:
    
    ```
    signal() {    S++;    if (S <= 0) {        wakeup(p);    }}
    
    ```
    

### 세마포 예제(Java)

```java
import java.util.concurrent.Semaphore;

public class Sem {
    static int sharedData = 0; // 공유 데이터
    // 세마포 생성, 공유 자원 1개
    static Semaphore semaphore = new Semaphore(1);

    public static void main(String[] args) {
        Thread thread1 = new Thread(new Increment());
        Thread thread2 = new Thread(new Decrement());

        thread1.start();
        thread2.start();

        try {
            thread1.join();
            thread2.join();
        } catch (InterruptedException e) {
            e.printStackTrace();
        }

        System.out.println("Final value of sharedData: " + sharedData);
    }

    static class Increment implements Runnable {
        public void run() {
            for (int i = 0; i < 100000; i++) {
                try {
                    semaphore.acquire();   // 세마포 획득
                    sharedData++;          // 공유 데이터 증가
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    semaphore.release();   // 세마포 해제
                }
            }
        }
    }

    static class Decrement implements Runnable {
        public void run() {
            for (int i = 0; i < 100000; i++) {
                try {
                    semaphore.acquire();   // 세마포 획득
                    sharedData--;          // 공유 데이터 감소
                } catch (InterruptedException e) {
                    e.printStackTrace();
                } finally {
                    semaphore.release();   // 세마포 해제
                }
            }
        }
    }
}

```

### 이진 세마포와 카운팅 세마포

- **이진 세마포**(binary semaphore): S가 0과 1의 값만 가질 수 있는 세마포
- **카운팅 세마포**(counting semaphore): S가 0 이상의 정수 값을 가질 수 있는 세마포

### 조건 변수와 모니터

- **조건 변수**(Condition Variable): 실행 순서 제어를 위한 동기화 도구
    - wait(): 호출한 프로세스/스레드를 대기 상태로 전환
    - signal(): wait()로 일시 중지된 프로세스/스레드 실행 재개
- **모니터**(Monitor): 공유 자원과 그 자원을 다루는 함수로 구성된 동기화 도구
    - 상호 배제와 실행 순서 제어 모두 가능
    - 모니터 내에는 항상 하나의 프로세스/스레드만 존재

### 조건 변수 예제(C++)

```cpp
#include <iostream>
#include <pthread.h>
#include <unistd.h>

// 뮤텍스와 조건 변수 해제
    pthread_mutex_destroy(&mutex);
    pthread_cond_destroy(&cond);
    return 0;
}

```

실행 결과:

```
P1: 먼저 시작
P1: 2초 대기
P2: 2초 실행 시작
P2: 실행 완료
P1: 다시 시작
P1: 종료

```

### 스레드 안전

- **스레드 안전**(Thread Safety): 멀티스레드 환경에서 여러 스레드가 동시에 접근해도 문제가 없는 상태
- 레이스 컨디션이 발생하면 스레드 안전하지 않은 상황
- 프로그래밍 언어의 표준 라이브러리 중 일부는 스레드 안전을 보장

### 스레드 안전 예제(Java)

```java
import java.util.*;

public class ThreadSafe {
    public static void main(String[] args) throws InterruptedException {
        // ArrayList와 Vector 생성
        List<Integer> arrayList = new ArrayList<>();
        List<Integer> vector = new Vector<>();

        // ArrayList와 Vector에 요소를 추가하는 스레드 생성
        Thread arrayListThread1 = new Thread(() -> addElements(arrayList, 0, 5000));
        Thread arrayListThread2 = new Thread(() -> addElements(arrayList, 5000, 10000));
        Thread vectorThread1 = new Thread(() -> addElements(vector, 0, 5000));
        Thread vectorThread2 = new Thread(() -> addElements(vector, 5000, 10000));

        arrayListThread1.start();
        arrayListThread2.start();
        vectorThread1.start();
        vectorThread2.start();

        arrayListThread1.join();
        arrayListThread2.join();
        vectorThread1.join();
        vectorThread2.join();

        System.out.println("ArrayList size: " + arrayList.size());
        System.out.println("Vector size: " + vector.size());
    }

    private static void addElements(List<Integer> list, int start, int end) {
        for (int i = start; i < end; i++) {
            list.add(i);
        }
    }
}

```

실행 결과:

```
ArrayList size: 5012
Vector size: 10000

```

### 교착 상태(데드락)

- **정의**: 프로세스들이 서로의 자원을 무한정 기다려 진행이 멈춘 상태
- **발생 조건**(4가지 조건이 모두 충족되어야 발생):

### 1. 상호 배제

- 한 번에 하나의 프로세스만 자원을 사용 가능한 상황
- 한 프로세스가 사용하는 자원을 다른 프로세스가 사용할 수 없음

### 2. 점유와 대기

- 자원을 보유한 상태에서 다른 자원을 기다리는 상황
- 프로세스가 어떤 자원을 할당받은 상태에서 다른 자원을 요청

### 3. 비선점

- 할당된 자원을 강제로 빼앗을 수 없는 경우
- 자원을 사용 중인 프로세스가 작업을 마칠 때까지 다른 프로세스는 기다려야 함

### 4. 원형 대기

- 프로세스들이 원형으로 자원을 기다리는 상황
- 예: 프로세스 A는 자원 X를 점유하고 자원 Y를 대기, 프로세스 B는 자원 Y를 점유하고 자원 X를 대기

### 교착 상태 해결 방법

- **예방**: 교착 상태 발생 조건 중 하나를 방지
    - 상호 배제 조건 제거: 여러 프로세스가 공유 자원 동시 사용 허용(불가능한 경우 많음)
    - 점유와 대기 조건 제거: 필요한 자원을 한 번에 모두 할당
    - 비선점 조건 제거: 자원 선점 허용
    - 원형 대기 조건 제거: 자원에 번호 부여하고 오름차순으로만 할당
- **회피**: 안전한 상태를 유지하는 자원 할당
    - 은행원 알고리즘(banker's algorithm): 자원 할당 전 안전성 검사
- **검출 및 회복**: 교착 상태 발생 시 감지하고 해결
    - 자원 선점: 교착 상태가 해결될 때까지 자원 강제 회수
    - 프로세스 강제 종료: 교착 상태에 있는 프로세스 종료

## 5. CPU 스케줄링

### CPU 스케줄링 개념

- **정의**: 프로세스에 CPU 자원을 배분하는 방법
- **목적**: CPU 활용률 최대화, 처리량 증가, 대기 시간 감소

### 기본 개념

- **우선순위**: 프로세스별 CPU 할당 순서 결정
    - 입출력 집중 프로세스(I/O-bound process): 입출력 작업이 많은 프로세스, 일반적으로 높은 우선순위
    - CPU 집중 프로세스(CPU-bound process): CPU 연산이 많은 프로세스, 일반적으로 낮은 우선순위
- **CPU 버스트와 입출력 버스트**:
    - CPU 버스트: 프로세스가 CPU를 이용하는 작업
    - 입출력 버스트: 프로세스가 입출력장치를 기다리는 작업
- **스케줄링 큐**: 프로세스들이 CPU 등 자원을 기다리는 줄
    - 준비 큐(ready queue): CPU를 이용하고 싶은 프로세스의 PCB가 서는 줄
    - 대기 큐(waiting queue): 대기 상태에 있는 프로세스의 PCB가 서는 줄
- **선점형/비선점형 스케줄링**:
    - 선점형(preemptive): 실행 중인 프로세스로부터 CPU 자원을 강제로 빼앗을 수 있음
    - 비선점형(non-preemptive): 실행 중인 프로세스가 스스로 CPU를 반환할 때까지 기다림

### CPU 스케줄링 알고리즘

### 1. 선입 선처리(FCFS, First-Come First-Served)

- **특징**: 먼저 요청한 프로세스부터 처리하는 비선점형 스케줄링
- **문제점**: 호위 효과(convoy effect) - 긴 작업이 먼저 실행되면 짧은 작업들의 대기 시간 증가

### 2. 최단 작업 우선(SJF, Shortest Job First)

- **특징**: 실행 시간이 가장 짧은 프로세스부터 처리하는 비선점형 스케줄링
- **단점**: 실행 시간이 긴 프로세스는 계속해서 밀려날 수 있음(기아 현상)

### 3. 라운드 로빈(RR, Round Robin)

- **특징**: 각 프로세스에 동일한 시간(타임 슬라이스)을 할당하는 선점형 스케줄링
- **장점**: 모든 프로세스에 공정하게 CPU 시간 분배
- **타임 슬라이스**: 프로세스가 CPU를 사용하도록 정해진 시간
    - 너무 짧으면 문맥 교환 오버헤드 증가
    - 너무 길면 FCFS와 유사해짐

### 4. 최소 잔여 시간 우선(SRT, Shortest Remaining Time)

- **특징**: SJF + 라운드 로빈의 특성을 가진 선점형 스케줄링
- **동작**: 남은 실행 시간이 가장 짧은 프로세스 우선 실행

### 5. 우선순위 스케줄링(Priority Scheduling)

- **특징**: 우선순위가 높은 프로세스부터 처리하는 스케줄링
- **문제점**: 우선순위가 낮은 프로세스의 기아 현상(starvation) 발생 가능
- **해결책**: 에이징(aging) 기법 - 오래 기다린 프로세스의 우선순위를 점차 높임

### 6. 다단계 큐(Multilevel Queue)

- **특징**: 우선순위별로 여러 준비 큐를 사용하는 스케줄링
- **동작**: 높은 우선순위 큐의 프로세스부터 처리
- **문제점**: 낮은 우선순위 큐의 프로세스 기아 현상 발생 가능

### 7. 다단계 피드백 큐(Multilevel Feedback Queue)

- **특징**: 다단계 큐 + 큐 간 이동 가능한 스케줄링
- **동작**:
    - 새로운 프로세스는 항상 가장 높은 우선순위 큐에 삽입
    - 타임 슬라이스 동안 실행이 끝나지 않으면 다음 우선순위 큐로 이동
    - 낮은 우선순위 큐에서 오래 기다린 프로세스는 에이징을 통해 상위 큐로 이동 가능
- **장점**: CPU 집중 프로세스는 자연스럽게 우선순위가 낮아지고, 입출력 집중 프로세스는 높은 우선순위를 유지

### 리눅스 CPU 스케줄링

- **CFS(Completely Fair Scheduler)**: 공정성 기반 스케줄러
- **vruntime**: 프로세스의 가상 실행 시간
    - 가중치에 따라 조정됨
    - vruntime이 작을수록 먼저 스케줄링됨
- **타임 슬라이스 계산**:
    
    ```
    타임 슬라이스 = (프로세스의 가중치 / 전체 가중치) * 전체 타임 슬라이스
    
    ```
    
- **스케줄링 정책**:
    - SCHED_FIFO: 실시간성 프로세스에 적용되는 FIFO 정책
    - SCHED_RR: 실시간성 프로세스에 적용되는 라운드 로빈 정책
    - SCHED_NORMAL: 일반적인 프로세스에 적용되는 정책(CFS)
    - SCHED_BATCH: 일반적인 프로세스만큼 자주 선점하지 않는 배치 작업 정책
    - SCHED_IDLE: 우선순위가 매우 낮은 프로세스에 적용되는 정책
- **RB 트리**: vruntime이 가장 작은 프로세스를 빠르게 선별하기 위한 자료구조

## 6. 가상 메모리

### 메모리 주소

- **물리 주소**(Physical Address): 실제 메모리 하드웨어 상의 주소
- **논리 주소**(Logical Address): 프로세스가 사용하는 가상의 주소 체계
    - 각 프로세스마다 0번지부터 시작하는 주소 체계
- **MMU**(Memory Management Unit): 논리 주소를 물리 주소로 변환하는 하드웨어

### 스와핑

- **정의**: 프로세스를 메모리와 보조기억장치(스왑 영역) 간에 교체하는 기법
- **스왑 아웃**(Swap Out): 메모리→스왑 영역으로 이동
- **스왑 인**(Swap In): 스왑 영역→메모리로 이동
- **목적**: 메모리 공간 확보 및 효율적인 메모리 관리

### 메모리 할당

- **연속 메모리 할당**(Contiguous Memory Allocation): 프로세스에 연속적인 메모리 공간 할당
- **외부 단편화**(External Fragmentation): 프로세스 사이에 발생하는 사용할 수 없는 작은 메모리 공간
    - 예: 30MB, 20MB 공간이 분리되어 있어 50MB 프로세스를 적재할 수 없는 상황

### 가상 메모리

- **정의**: 실제 메모리보다 더 큰 프로그램 실행을 가능하게 하는 기법
- **장점**:
    - 물리 메모리 크기 제약 극복
    - 효율적인 메모리 관리
    - 다중 프로그래밍의 효율성 향상

### 페이징

- **정의**: 프로세스의 논리 주소 공간을 페이지 단위로 나누어 관리하는 가상 메모리 기법
- **페이지**(Page): 논리 메모리를 일정한 크기로 나눈 단위
- **프레임**(Frame): 물리 메모리를 페이지와 동일한 크기로 나눈 단위
- **장점**:
    - 외부 단편화 해결
    - 불연속적인 메모리 할당 가능
    - 실제 메모리보다 큰 프로그램 실행 가능

### 페이지 테이블

- **정의**: 페이지와 프레임의 매핑 정보를 저장하는 테이블
- **구성 요소**:
    - 페이지 번호
    - 프레임 번호
    - 유효 비트: 페이지가 메모리에 있는지 여부(1: 메모리에 있음, 0: 없음)
    - 보호 비트: 페이지 접근 권한(r: 읽기, w: 쓰기, x: 실행)
    - 참조 비트: 페이지 접근 여부
    - 수정 비트(더티 비트): 페이지 내용 변경 여부
- **페이지 폴트**(Page Fault): 접근하려는 페이지가 메모리에 없을 때 발생하는 예외
- **페이지 폴트 처리 과정**:
    1. CPU가 기존 작업 내역 백업
    2. 페이지 폴트 처리 루틴 실행(보조기억장치에서 해당 페이지를 메모리로 가져옴)
    3. 페이지 테이블 업데이트(유효 비트를 1로 변경)
    4. 작업 재개

### 내부 단편화

- **정의**: 페이지 하나의 크기보다 작은 크기로 발생하는 메모리 낭비
- **예**: 페이지 크기가 10KB인데 프로세스의 크기가 107KB라면, 마지막 페이지는 3KB만 사용되고 7KB가 낭비됨

### TLB(Translation Lookaside Buffer)

- **정의**: 페이지 테이블의 캐시
- **목적**: 메모리 접근 성능 향상
- **동작 방식**:
    - TLB 히트: 페이지 번호가 TLB에 있어 직접 프레임 번호를 얻는 경우
    - TLB 미스: 페이지 번호가 TLB에 없어 페이지 테이블에서 프레임 번호를 찾아야 하는 경우

### 계층적 페이징

- **정의**: 페이지 테이블을 여러 단계로 구성하는 기법
- **목적**:
    - 메모리 접근 횟수 감소
    - 메모리 용량 효율화
- **동작**: 외부 페이지 테이블(Outer Page Table)이 내부 페이지 테이블을 가리킴

### 페이징 주소 체계

- **논리 주소**: <페이지 번호, 변위>
- **물리 주소**: <프레임 번호, 변위>
- **주소 변환 과정**:
    1. 논리 주소에서 페이지 번호와 변위 추출
    2. 페이지 테이블에서 페이지 번호에 해당하는 프레임 번호 검색
    3. 프레임 번호와 변위를 결합하여 물리 주소 생성

### 페이지 교체 알고리즘

- **목적**: 메모리가 가득 찼을 때 어떤 페이지를 스왑 아웃할지 결정

### FIFO 페이지 교체 알고리즘

- **특징**: 가장 먼저 메모리에 적재된 페이지부터 교체
- **장점**: 구현이 간단
- **단점**: 자주 사용되는 페이지도 교체될 수 있음

### 최적 페이지 교체 알고리즘

- **특징**: 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체
- **장점**: 최소의 페이지 폴트 발생
- **단점**: 미래 참조를 예측하기 어려워 실제 구현 불가능

### LRU 페이지 교체 알고리즘

- **특징**: 가장 오랫동안 사용되지 않은 페이지를 교체
- **장점**: 참조 지역성을 활용한 효율적인 알고리즘
- **단점**: 구현 복잡성

### 페이지 폴트의 종류

- **메이저 페이지 폴트**(Major Page Fault): 보조기억장치에서 페이지를 읽어와야 하는 경우
- **마이너 페이지 폴트**(Minor Page Fault): 물리 메모리에 페이지가 존재하지만 페이지 테이블에 반영되지 않은 경우

### 스래싱(Thrashing)

- **정의**: 프로세스가 실제 작업보다 페이징에 더 많은 시간을 소요하는 현상
- **원인**: 너무 많은 프로세스 실행으로 인한 과도한 페이지 교체
- **해결책**: 메모리 증설, 실행 프로세스 수 제한, 작업 세트 모델 적용

## 7. 파일 시스템

### 파일

- **정의**: 보조기억장치에 저장된 관련 정보의 집합
- **구성**:
    - 파일 이름
    - 실행 정보
    - 속성(메타데이터): 파일 형식, 위치, 크기, 접근 권한, 생성/수정/접근 시간 등
- **파일 속성 예시**:
    
    ```
    $ stat ./sample
    File: "sample"
    Size: 16696        Blocks: 40      IO Block: 4096  regular file
    Device: 10302h/66306d    Inode: 1837330    Links: 1
    Access: (0775/-rwxrwxr-x)  Uid: ( 1000/ minchul)   Gid: ( 1000/ minchul)
    Access: 2024-03-17 23:15:52.400896517 +0900
    Modify: 2024-03-17 23:15:30.916896007 +0900
    Change: 2024-03-17 23:15:30.916896007 +0900
    Birth: -
    
    ```
    
- **파일 디스크립터**(File Descriptor): 프로세스가 파일을 식별하는 정보
    - 0 이상의 정수 형태
    - 표준 입력(0), 표준 출력(1), 표준 에러(2)는 기본 할당됨
    - 시스템 콜 `open()`, `read()`, `write()`, `close()` 등에서 사용

### 파일 디스크립터 예제

```c
#include <stdio.h>
#include <fcntl.h>
#include <unistd.h>

int main() {
    char text[] = "Hello, world!";

    // 파일을 열고 파일 디스크립터를 반환받음
    int file_descriptor1 = open("example.txt", O_WRONLY);
    printf("파일 디스크립터: %d\n", file_descriptor1);
    int file_descriptor2 = open("example2.txt", O_WRONLY);
    printf("파일 디스크립터: %d\n", file_descriptor2);
    int file_descriptor3 = open("example3.txt", O_WRONLY);
    printf("파일 디스크립터: %d\n", file_descriptor3);

    // 파일에 문자열 쓰기
    write(file_descriptor1, text, sizeof(text) - 1);
    write(file_descriptor2, text, sizeof(text) - 1);
    write(file_descriptor3, text, sizeof(text) - 1);

    // 파일 디스크립터를 통해 파일을 닫음
    close(file_descriptor1);
    close(file_descriptor2);
    close(file_descriptor3);
    return 0;
}

```

실행 결과:

```
파일 디스크립터: 3
파일 디스크립터: 4
파일 디스크립터: 5

```

### 디렉터리

- **정의**: 파일과 다른 디렉터리를 포함하는 특별한 파일
- **구조**: 트리 구조로 계층적 관리
    - 루트 디렉터리("/")부터 시작하는 계층 구조
    - 슬래시("/")는 디렉터리 구분자로 사용(윈도우는 백슬래시(""))
- **디렉터리 엔트리**(Directory Entry): 디렉터리에 속한 요소의 관련 정보
    - 파일 이름
    - 파일이 저장된 위치를 유추할 수 있는 정보(아이노드 번호 등)
    - 일부 파일 시스템에서는 파일 속성도 포함
- **리눅스 디렉터리 엔트리 구조**:
    
    ```c
    struct dirent {
        ino_t d_ino;           // 파일의 아이노드 번호
        off_t d_off;           // 현재 디렉터리 엔트리의 오프셋
        unsigned short d_reclen; // 현재 디렉터리 엔트리의 길이
        unsigned char d_type;   // 파일 형식
        char d_name[256];      // 파일 이름
    };
    
    ```
    

### 파일 할당

- **블록**(Block): 운영체제가 파일과 디렉터리를 읽고 쓰는 단위 (일반적으로 4KB)

### 연결 할당

- **특징**: 각 블록이 다음 블록을 가리키는 형태로 파일 할당
- **디렉터리 엔트리**: 파일 이름, 첫 번째 블록 주소, 파일 길이 저장
- **장점**: 외부 단편화 없음
- **단점**: 순차 접근만 가능, 포인터로 인한 공간 낭비, 신뢰성 문제

### 색인 할당

- **특징**: 색인 블록에 파일의 모든 블록 주소를 저장
- **디렉터리 엔트리**: 파일 이름, 색인 블록 주소 저장
- **장점**: 직접 접근 가능, 외부 단편화 없음
- **단점**: 작은 파일에 비효율적

### 파일 시스템

- **정의**: 파일과 디렉터리를 관리하는 운영체제 프로그램
- **종류**:
    - Windows: NTFS, ReFS
    - Linux: EXT4, XFS, ZFS
    - macOS: APFS

### 파티셔닝

- **정의**: 보조기억장치의 영역을 구획하는 작업
- **파티션**(Partition): 파티셔닝으로 나누어진 하나의 영역
- **목적**: 여러 파일 시스템 사용, 영역 분리로 데이터 안전성 확보

### 포맷팅

- **정의**: 파일 시스템을 설정하고 새로운 데이터를 쓸 준비를 하는 작업
- **과정**: 파일 시스템 종류 선택 및 초기화

### 아이노드 기반 파일 시스템

- **아이노드**(inode): 파일의 모든 정보를 저장하는 색인 블록
    - 파일의 속성, 저장된 위치 등 정보 포함
    - 파일 이름은 제외(디렉터리 엔트리에 저장)
- **아이노드 번호 확인**:
    
    ```
    $ ls -litotal 25222558957 drwxrwxr-x 2 minchul minchul 4096 11월 21 2022 bcc22563646 drwxrwxr-x 17 minchul minchul 4096 10월 5 2022 buildroot22547742 -rw-r--r-- 1 minchul minchul 196 11월 11 2022 Fibonacci.c...
    
    ```
    

### EXT4 파일 시스템 구성

- **부트 블록**: 부팅과 파티션 관리를 위한 정보
- **블록 그룹**: 여러 블록의 그룹
    - 슈퍼 블록: 파일 시스템의 전체적인 정보 저장
    - 그룹 식별자: 블록 그룹에 대한 메타데이터
    - 블록 비트맵: 데이터 블록 할당 정보
    - 아이노드 비트맵: 아이노드 할당 정보
    - 아이노드 테이블: 파일의 아이노드 정보
    - 데이터 블록: 실제 파일 데이터 저장

### 하드 링크와 심볼릭 링크

- **하드 링크**(Hard Link):
    - 같은 아이노드를 참조하는 여러 파일 이름
    - 원본 파일과 동일한 데이터 공유
    - 원본 파일이 삭제되어도 데이터 접근 가능
- **심볼릭 링크**(Symbolic Link):
    - 원본 파일의 경로를 가리키는 특수 파일
    - 원본 파일의 위치만 저장
    - 원본 파일이 삭제되면 접근 불가능
    - 윈도우의 바로가기 파일과 유사

### 마운트

- **정의**: 다른 파일 시스템을 기존 파일 시스템에 연결하는 작업
- **목적**: 외부 저장장치 접근, 네트워크 파일 시스템 접근
- **마운트 포인트**: 다른 파일 시스템이 연결되는 디렉터리
- **리눅스 마운트 명령어**:
(-t: 파일 시스템 타입, -o: 옵션(ro: 읽기 전용), /dev/sda: 장치, /mnt/test: 마운트 포인트)
    
    ```
    # mount -t ext4 -o ro /dev/sda /mnt/test
    
    ```
    

## 8. 부팅 과정

### 전원 인가부터 운영체제 로딩까지

1. **BIOS/UEFI 실행**:
    - 전원이 켜지면 CPU는 ROM에 저장된 BIOS/UEFI 프로그램을 실행
    - UEFI(Unified Extensible Firmware Interface)는 대용량 환경에서 부팅 가능하고, 빠른 부팅, 그래픽 인터페이스 제공
2. **POST(Power-On Self Test)**:
    - 하드웨어 검사
    - 문제가 있는지 확인
3. **부트로더 로드**:
    - MBR(Master Boot Record)에서 부트로더(bootstrap) 실행
    - MBR은 보조기억장치의 첫 부분(첫 번째 섹터)에 위치
4. **커널 로드**:
    - 부트로더가 운영체제 커널을 메모리에 로드
    - 커널은 메모리에 적재되어 초기화
5. **운영체제 초기화**:
    - 장치 드라이버 로드
    - 시스템 설정
    - 사용자 인터페이스 시작

## 9. 가상화 기술

### 가상 머신

- **정의**: 소프트웨어로 구현된 가상의 컴퓨터
- **하이퍼바이저**(Hypervisor): 가상 머신을 생성하고 관리하는 소프트웨어
    - VirtualBox, VMware, Hyper-V 등
- **특징**:
    - 하드웨어 수준의 자원 격리
    - 다양한 OS 실행 가능
    - 각 가상 머신마다 독립적인 운영체제 실행
- **단점**:
    - 오버헤드 크고 자원 소모 많음
    - 속도가 상대적으로 느림

### 컨테이너

- **정의**: OS 수준의 가상화 기술
- **특징**:
    - 호스트 OS 커널 공유
    - 애플리케이션과 필요한 라이브러리만 포함
    - 가볍고 빠름
    - 효율적인 자원 사용
- **예시**: Docker, LXC
- **사용 규모**: 구글에서는 매주 40억 개 이상의 컨테이너 실행

### 컨테이너 오케스트레이션

- **정의**: 다양한 컨테이너를 관리하는 기술
- **기능**:
    - 자동 배포
    - 환경에 맞게 컨테이너 수 조절
    - 컨테이너 간 네트워크 구성
- **예시**: Kubernetes(k8s)

# 운영체제 추가 정리 내용

## 추가 질문 및 답변

### Q: 스래싱이 일어나면 다른 또 중요한 작업(네트워크 작업)도 더뎌질수 있는지?
스래싱은 단순히 메모리 관리에만 문제를 일으키는 것이 아니다. 네트워크 작업을 포함한 전체 시스템 성능에 광범위한 영향을 미친다. 네트워크 스택 처리, 버퍼 관리, 인터럽트 처리가 지연되어 네트워크 타임아웃이 발생할 수 있다. 결과적으로 전반적인 시스템 응답성이 크게 저하된다.

### Q: 연속 메모리 할당이 참조 지역성의 원리와 관련이 있는지? 있다면 왜 있는지?
연속 메모리 할당은 참조 지역성의 원리와 밀접한 관련이 있다. 프로그램 코드와 데이터를 연속된 메모리 공간에 할당하면 공간 지역성 활용에 유리하다. 이로 인해 캐시 성능이 향상되고 페이지 폴트가 감소하는 효과가 있다. 특히 배열 같은 데이터 구조에 접근할 때 캐시 히트율이 높아진다.

### Q: 페이지 테이블을 조회하는 부분이 정확히 어느 시점에 일어나는지?
페이지 테이블 조회는 CPU가 논리 주소를 사용하여 메모리 접근 명령을 실행할 때마다 발생한다. 명령어 실행 파이프라인의 메모리 접근 단계 전에 이루어진다. 또한 명령어 인출 단계에서도 같은 과정이 필요하다.

### Q: TLB는 어디에 위치하고 있길래 더 빠른건지?
TLB는 CPU 내부 또는 CPU 칩 내의 MMU 안에 위치하여 CPU 코어와 매우 가깝다. 고속 연관 메모리로 구현되어 병렬 검색이 가능하며, 적은 수의 엔트리로 구성되어 빠른 검색이 가능하다. TLB 접근은 1 CPU 사이클 이내인 반면, 메인 메모리 접근은 수십~수백 CPU 사이클이 소요된다. 이러한 위치적, 구조적 특성 때문에 TLB가 더 빠르다.

### Q: TLB도 정확히 어느 시점에 이루어지는건지?
TLB 조회는 CPU가 메모리 참조 명령을 실행할 때마다 MMU에 의해 자동으로 수행되며, 페이지 테이블 조회 직전에 이루어진다. 논리 주소에서 페이지 번호를 추출한 후 TLB에서 검색한다. 히트 시 바로 물리 주소를 생성하고, 미스 시 페이지 테이블에 접근한다.

### Q: 페이지 폴트는 느린데 그럼 언제 쓰는 게 좋은지?
페이지 폴트는 느리지만 요구 페이징, 메모리 오버커밋, 지연 로딩, Copy-on-Write 등의 시나리오에서 효율적으로 활용할 수 있다. 이를 통해 초기 메모리 적재 시간을 단축하고, 물리적 메모리보다 많은 가상 메모리를 할당할 수 있다. 또한 필요할 때까지 데이터 로딩을 지연시키고, 불필요한 메모리 복사를 방지하는 이점을 얻을 수 있다.