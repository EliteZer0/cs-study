# 1. 컴퓨터가 이해하는 정보

컴퓨터 내부에서 정보는 0과 1의 조합으로 표현하고 처리된다.

이는 정보 처리의 가장 기본적인 단위이다.

- **비트**(Bit)
  - 컴퓨터가 이해하는 가장 작은 정보 단위이다.
  - 'binary digit'의 줄임말로, 0과 1의 두 가지 값을 가질 수 있다.
  - 컴퓨터 내부의 모든 데이터와 명령어는 궁극적으로 비트의 연속으로 표현된다.
- **바이트**(Byte)
  - 여러 개의 비트가 모여 의미 있는 단위가 되는데, 그중 가장 대표적인 것이다.
  - 8개의 비트가 모여서 하나의 바이트를 형성한다.
  - 영어 알파벳 문자 하나, 숫자 하나, 또는 특수 문자 하나 등을 표현하기에 충분한 크기이다.
  - 데이터 크기를 나타내는 기본 단위로 널리 사용됨
  - 킬로바이트(KB), 메가바이트(MB), 기가바이트(GB) 등
- **워드**(Word)
  - CPU가 한 번에 처리할 수 있는 데이터의 크기이다.
  - 워드 크기는 CPU 설계에 따라 결정된다.
  - 예를 들어, 32비트 CPU는 32비트(4바이트)를, 64비트 CPU는 64비트(8바이트)를 한 번에 처리할 수 있다.
  - 즉 CPU가 한 번에 32비트를 처리할 수 있다면 32비트가 1워드, 64비트 CPU가 한 번에 64비트를 처리할 수 있다면 64비트가 된다.
  - 워드의 크기가 클수록 CPU는 더 많은 데이터를 한 번에 다룰 수 있기 때문에 일반적으로 더 높은 성능을 기대할 수 있다.

## 데이터 - 0과 1로 숫자 표현하기

2진법, 10진법, 16진법, 소수 표현법, 부동 소수점, 지수, 가수, m*2^n, 2의 지수가 양수인 경우, 2의 지수가 음수인 경우, IEEE 754, 정규화한 수, 소수 부분, 바이어스, 10진수 소수를 2진수로 표현할 때 10진수 소수와 2진수 소수의 표현이 딱 맞아 떨어지지 않음, 

### 기본 진법 시스템

- **2진법**(Binary)
  - 컴퓨터는 전자 회로의 ON/OFF 상태를 표현하기 가장 용이한 2진법을 기본 연산 체계로 사용한다.
  - 모든 데이터와 명령어는 내부적으로 0과 1의 나열로 처리된다. 
- **10진법**(Decimal)
  - 우리가 일상생활에서 사용하는 숫자 체계이다.
  - 컴퓨터는 사용자로부터 10진수 입력을 받거나 결과를 10진수로 출력하기 위해 내부적으로 변환 과정을 거친다.
- **16진법**(Hexadecimal)
  - 2진수를 4비트씩 묶어 표현하므로, 긴 2진수 문자열을 간결하게 나타낼 수 있다.
  - 메모리 주소나 데이터 값을 표현할 때 자주 사용된다(0-9, A-F).

### 실수 표현의 필요성과 부동 소수점

- **실수 표현의 필요성**
  - 정수 표현만으로는 모든 실수를 표현할 수 없다.
  - 예를 들어, 1/3, 0.1 등의 숫자는 정확히 표현할 수 없다.
  - 이는 고정된 비트 수 내에서 매우 큰 수부터 매우 작은 소수까지 넓은 범위를 표현해야 하기 때문이다.
- **부동 소수점**
  - 위를 해결하기 위해 고안된 방식이다.
  - 이름처럼 소수점의 위치가 고정되지 않고 떠다니는(floating) 방식으로 수를 표현한다.
  - 과학적 표기법과 유사하게 수를 가수(mantissa)와 지수(exponent)로 분리하여 표현한다.
  - 값 = 가수 * 밑^지수
  - 예를 들어, 123.456은 1.23456 * 10^2 와 같이 표현할 수 있다.
  - 이렇게 표현하면 매우 큰 수나 매우 작은 수를 표현할 수 있고, 더 정확한 수를 표현할 수 있다.  
  
### 부동 소수점의 구성 요소 상세

- **가수**
  - 수의 유효 숫자 부분을 저장한다.
  - 수의 정밀도와 관련된다.
  - **정규화**
    - 표현의 유일성을 보장하고 비트 사용 효율을 높이기 위해 가수 부분을 특정 형식으로 변환한다.
    - 일반적으로 0이 아닌 실수는 1.xxxx... * 2^n 형태로 정규화된다.
    - 이렇게 하면 가수의 첫번째 비트는 항상 1이 된다(암묵적 비트).
    - 이 비트를 생략하고 소수 부분만 저장해 표현할 수 있는 정밀도를 한 비트 더 늘릴 수 있다 -> IEEE 754 표준 방식
- **지수**
  - 수의 크기 또는 척도를 나타낸다.
  - 즉 소수점의 실제 위치를 결정한다.
  - 지수 n이 양수이면 2^n 만큼 수가 커지고(소수점이 오른쪽으로 이동)
  - 음수이면 2^n 만큼 수가 작아진다(소수점이 왼쪽으로 이동).
  - **바이어스 표현**
    - 지수 자체도 양수, 0, 음수가 될 수 있다.
    - 하지만 지수를 저장할 땐 음수 표현의 복잡성을 피하기 위해 실제 지수 값에 특정 바이어스 값을 더해 항상 음수가 아닌 정수 형태(unsigned integer)로 저장한다.
    - 예를 들어, 8비트 지수부에서 바이어스가 127이라면, 실제 지수 0은 127로, 실제 지수 -1은 126으로, 실제 지수 1은 128로 저장된다.
    - 나중에 실제 지수 값을 계산할 땐 저장된 값에서 바이어스를 다시 빼준다.

### IEEE 754 표준

- 컴퓨터 시스템에서 부동 소수점 표현과 연산 방식을 정의하는 국제 표준이다.
- 주요 형식
  - **단정밀도(float)**: 32비트(부호 1비트, 지수 8비트, 가수 23비트) 사용
  - **배정밀도(double)**: 64비트(부호 1비트, 지수 11비트, 가수 52비트) 사용
- 무한대, NaN과 같은 특수한 값들의 표현 및 처리 방식도 정의한다.

### 2진 소수 표현의 한계

- **무한 반복 소수**
  - 10진법에서는 유한 소수인 많은 수가 2진법으로 변환하면 **무한 반복 소수**가 된다.
  - 가장 대표적인 예가 10진수 0.1이다.
  - 이는 2진수로 0.0001100110011...(2)와 같이 0011이 무한히 반복되는 형태로 표현된다.
- **근사값**
  - 컴퓨터는 유한한 비트 수만을 사용해 가수를 저장하므로, 무한 소수는 특정 지점에서 잘라내 근사값으로 표현할 수밖에 없다.
  - 예를들어 10진수 0.1을 IEEE 754 단정밀도(float) 형식으로 표현하면 가수 부분은 10011001100110011001101(2) 와 같이 23비트로 표현된다.
- 이처럼 2진 부동 소수점 시스템에서 정확한 값이 아닌 근사값으로 표현되기 때문에, 0.1을 여러 번 더하는 등 연산을 수행할 때 **정밀도 오류** 및 **반올림 오류**가 발생할 수 있다.

## 데이터 - 0과 1로 문자 표현하기

문자 집합, 문자 인코딩, 문자 디코딩, 아스키, 패리티 비트, 아스키 코드표, 아스키 코드, EUC-KR, 2바이트, 아직도 모든 한글 조합을 표현할 수 있을 정도로 많은 양은 아님, 유니코드, 통일된 문자 집합, 가변 길이 인코딩, 패딩, 

### 문자 처리 기본 개념

- **문자 집합**
  - 컴퓨터가 인식할 수 있는 모든 문자 목록이다.
  - 단순히 '어떤 문자들을 사용할 것인가?'를 정의하는 단계
  - 예를 들어, 영문 알파벳벳 대소문자, 숫자 0-9, 특수 문자들, 한글, 한자, 일본어 등
- **문자 인코딩**
  - 정의된 문자 집합의 각 문자에 대해 컴퓨터가 저장하고 처리할 수 있는 고유한 숫자 값(주로 2진수 코드)을 대응시키는 규칙 또는 체계
  - 'A'는 65, '가'는 44032 와 같이 구체적인 숫자 값을 부여하는 과정임
  - 이 인코딩 규칙이 있어야 문자를 비트와 바이트 단위로 저장하고 전송할 수 있다.
- **문자 디코딩**
  - 문자 인코딩의 반대 과정이다.
  - 컴퓨터 메모리나 파일에 저장된 숫자 코드 값을 다시 원래의 문자로 해석하고 변환해 화면에 표시하거나 다른 프로그램에서 인식할 수 있도록 하는 과정이다.
  - 인코딩 방식과 디코딩 방식이 일치하지 않으면 다음과 같이 글자가 깨져 보이는 현상이 발생한다.
  ![image](./img/break-bsh.png)


### 초기 표준: 아스키(ASCII)

- 컴퓨터 초기에 가장 널리 사용된 문자 인코딩 표준이다.
- **아스키 코드표(ASCII Table)**
  - 0부터 127까지 총 128개의 코드 값을 정의해 각 코드 값에 해당하는 문자를 명시한 표이다.
  - 여기에는 영문 알파벳 대소문자, 숫자, 공백, 문장 부호, 프린터 제어 등이 포함된다.
  ![image](./img/asciitable-bsh.png)
- **아스키 코드(ASCII Code)**
  - 아스키 코드표에 따라 각 문자에 부여된 7비트 크기의 숫자 값
  - 예를 들어, 'A'는 65, 'B'는 66, 'a'는 97, 'b'는 98 와 같이 대응된다.
- **패리티 비트(Parity Bit)**
  - 데이터 전송 시 오류를 검출하기 위해 선택적으로 사용되던 1비트이다.
  - 7비트 아스키 코드에 1비트를 추가해 총 8비트(1바이트)를 만들고, 1의 개수가 짝수 혹은 홀수가 되도록 패리티 비트를 설정하는 방식(홀수 패리티, 짝수 패리티)으로 간단한 오류 검사를 수행했다.
- **한계**
  - 128개의 문자만 표현 가능하여 영어 이외 언어(한글, 한자, 유럽 특수 문자 등)를 표현할 수 없다.

### 지역별 인코딩 확장(EUC-KR)

- 아스키의 한계를 극복하고 각국의 언어를 표현하기 위해 다양한 인코딩 방식이 등장했다.
- 한글 표현을 위해 한국에서 주로 사용된 대표적인 인코딩 방식은 **EUC-KR** 이다.
- **특징**
  - 아스키 문자는 1바이트로 그대로 표현해 호환성을 유지하고, 한글 한 글자를 표현하기 위해서는 2바이트를 조합해 사용한다.
  - 첫 바이트는 특정 범위 내의 값을, 두 번째 바이트도 특정 범위 내의 값을 가진다.
- **한계**
  - 모든 현대 한글 음절(약 11,172자)을 표현할 수 있도록 설계되었지만, '쿯', '홥'과 ㅏㅌ이 사용 빈도가 낮은 일부 조합이나 옛 한글 등은 표현하지 못하는 경우가 있다.
  - 이는 미리 정의된 글자 조합에만 코드를 부여하는 **완성형 코드** 방식을 기반으로 했기 때문이다.
  - 또한 EUC-KR로 작성된 문서는 다른 언어권의 인코딩 방식(일본어 Shift-JIS, 중국어 GBK 등)과 호환되지 않아 국제적인 데이터 교환 시 문자 깨짐 문제가 자주 일어난다.

### 통합 표준: 유니코드 (Unicode)

- 전 세계의 모든 문자를 일관된 방식으로 표현하고 처리하기 위해 등장한 **국제 표준 문자 집합**이다.
- 특정 언어나 플랫폼에 종속되지 않는다.
- 지구상에 존재하는 대부분의 문자(현대 문자, 옛 문자, 기호, 이모지 등)에 대해 **전 세계적으로 교유한 코드 포인트**라는 숫자 값을 부여한다.
- 문자 인코딩의 혼란을 없애고, 어떤 언어의 문서라도 문제없이 읽고 쓸 수 있도록 **통일된 문자 집합**을 제공한다.
- 인코딩 방식 그 자체가 아니라, 각 문자에 부여된 고유한 '이름표'라고 생각해도 된다.

### 유니코드 인코딩 방식

- 유니코드 코드 포인트를 실제 컴퓨터 메모리에 저장하거나, 네트워크로 전송하기 위한 **바이트 단위의 표현 규칙**이다.
- 대표적인 유니코드 인코딩 방식으로는 UTF-8, UTF-16, UTF-32가 있다.
- **UTF-8(8-bit Unicode Transformation Format)**
  - 현재 웹과 대부분의 시스템에서 가장 널리 사용되는 인코딩 방식이다.
  - **가변 길이 인코딩**
    - 문자의 종류에 따라 사용하는 바이트 수가 달라진다.
    - 아스키 문자는 기존 아스키 코드와 동일하게 1바이트로 표현(하위 호환성)
    - 한글, 라틴 문자 확장, 그리스 문자 등은 주로 2, 3바이트로 표현
    - 다른 평면 문자(일부 한자, 이모지)는 4바이트 이상
  - 아스키와의 호환성이 뛰어나고, 영어 중심 문서에서는 저장 공간을 효율적으로 사용할 수 있다. 
- **UTF-16**
  - 주로 2바이트, 4바이트를 사용해 문자를 표현하는 가변 길이 인코딩 방식이다.
  - Windows 운영체제 내부 등에서 사용된다.
- **UTF-32**
  - 모든 문자를 항상 4바이트로 표현하는 고정 길이 인코딩 방식이다.
  - 처리가 단순하지만, 저장 공간 효율성은 떨어진다.

### 패딩

- 패딩은 데이터 처리 과정에서 특정 **데이터 블록의 길이를 맞추기 위해** 의미 없는 데이터(주로 0)를 덧붙이는 행위이다.
- 예를 들어, 암호화 알고리즘에서 특정 블록 크기(예: 16바이트)를 요구할 때, 원본 데이터가 이 크기보다 작으면 나머지를 패딩으로 채운다.
- 또는 데이터 구조에서 정렬을 위해 특정 위치에 패딩 바이트를 삽입하기도 한다.
- 문자 인코딩 자체에서 보다는 인코딩된 결과 문자열을 저장하거나 전송할 때 패딩이 사용된다.

## 명령어

수행할 동작, 수행할 대상, 데이터 자체, 데이터가 저장된 위치, 연산 코드, 오퍼랜드, 연산 코드에 사용될 데이터가 저장된 위치, 주소 필드, 데이터 전송, 산술/논리 연산, 제어 흐름 변경, 입출력 제어, 기계어, 어셈블리어, 명령어 사이클, 인출 사이클, 실행 사이클, 간접 사이클, 인터럽트 사이클, 

### 명령어의 기본 구조

- 컴퓨터 명령어는 CPU에게 **수행할 동작**과 **수행할 대상**을 알려주는 정보이다.
- **연산 코드 (Opcode / Operation Code)**
  - 명령어의 핵심 부분으로, CPU가 수행할 동작의 종류를 구체적으로 지정한다.
  - 종류에는 데이터를 옮기는 데이터 전송, 덧셈/뺄셈/논리곱/논리합 등의 산술/논리 연산, 프로그램의 실행 순서를 바꾸는 제어 흐름 변경(분기, 점프 등), 외부 장치와의 데이터 교환을 관리하는 입출력 제어 등이 있다.
- **오퍼랜드 (Operand)**
  - 연산 코드가 수행할 대상에 대한 정보를 담고 있다.
  - 데이터 자체를 직접 포함할 수도 있지만, 대부분의 경우 연산에 필요한 데이터가 저장된 위치(메모리 주소, 레지스터 번호 등)를 가리킨다.
  - 따라서 오퍼랜드는 연산 코드에 사용될 데이터가 저장된 위치를 명시하는 역할을 하며, 이 위치 정보 부분을 특히 주소 필드(Address Field)라고 부른다.

### 명령어의 표현

- **기계어 (Machine Code)**
  - CPU가 직접 이해하고 실행할 수 있는 유일한 형태의 명령어이다.
  - 0과 1의 이진수(Binary) 조합으로 표현되며, 연산 코드와 오퍼랜드 정보가 모두 이진 코드로 인코딩되어 있다.
  - 사람은 직접 읽고 이해하기 매우 어렵다.
- **어셈블리어 (Assembly Language)**
  - 기계어와 일대일로 대응되는 저수준 프로그래밍 언어이다.
  - 기계어의 이진 연산 코드 대신 사람이 이해하기 쉬운 니모닉(Mnemonic, 예: ADD, MOV, JMP)을 사용하고, 오퍼랜드의 위치(주소)도 숫자가 아닌 심볼(Symbolic Name, 예: 변수명)로 표현할 수 있다.
  - 어셈블리어 코드는 어셈블러(Assembler)라는 프로그램을 통해 기계어로 변환되어야 CPU에서 실행될 수 있다.

### 명령어 처리 과정: 명령어 사이클

- CPU는 프로그램을 실행하기 위해 메모리에서 명령어를 하나씩 가져와 처리하는 과정을 반복하는데, 이를 명령어 사이클이라 한다.
- 기본적인 명령어 사이클은 다음과 같은 단계들로 구성된다.
- **인출 사이클 (Fetch Cycle)**
  - CPU가 다음에 실행할 명령어를 메모리에서 가져오는 단계이다. 
  - 프로그램 카운터(PC)가 가리키는 주소의 명령어를 읽어와 명령어 레지스터(IR)에 저장한다.
- **실행 사이클 (Execute Cycle)**
  - 인출된 명령어의 연산 코드를 해독(Decode)하고, 오퍼랜드 정보를 이용해 지정된 동작(데이터 전송, 산술/논리 연산, 제어 흐름 변경 등)을 실제로 수행하는 단계이다.
- **간접 사이클 (Indirect Cycle)**
  - 명령어의 오퍼랜드(주소 필드)가 실제 데이터의 주소가 아닌, 데이터 주소가 저장된 또 다른 메모리 주소(간접 주소)를 가리키는 경우가 있다.
  - 이 경우, 데이터가 저장된 위치의 실제 주소를 알아내기 위해 메모리에 한 번 더 접근하는 단계가 필요한데, 이를 간접 사이클이라고 한다.
  - 간접 사이클은 실행 사이클 이전에 수행된다.
- **인터럽트 사이클 (Interrupt Cycle)**
  - 하나의 명령어 실행을 완료한 후, 다음 명령어를 인출하기 전에 인터럽트(Interrupt) 발생 여부를 확인하는 단계이다.
  - 인터럽트는 주로 입출력 제어와 관련하여 주변 장치로부터 예상치 못한 작업 요청이 들어왔을 때 발생하며, CPU는 현재 작업을 잠시 멈추고 인터럽트 처리 루틴을 먼저 실행하게 된다.
  - 인터럽트 처리가 끝나면 원래 작업으로 복귀한다.

# 2. CPU

## 레지스터

**레지스터**는 CPU 내부에 위치한 매우 빠른 임시 저장 공간이다.

메모리(RAM)보다 훨씬 빠르게 접근할 수 있기 때문에, CPU가 현재 처리 중인 데이터나 명령어, 연산 결과 등을 일시적으로 보관하는 중요한 역할을 수행한다.

레지스터는 그 용도에 따라 여러 종류로 나뉜다.

### 특수 목적 레지스터

- **프로그램 카운터 (Program Counter, PC)**
  - CPU가 다음으로 실행해야 할 명령어의 메모리 주소를 저장하고 있는 레지스터이다. 
  - 즉, 메모리에서 다음으로 읽어들일 명령어의 주소를 가리킨다.
  - 명령어가 하나 실행될 때마다 자동으로 다음 명령어를 가리키도록 주소값이 증가하거나, 분기(jump) 명령어에 의해 특정 주소로 변경된다.
  - **명령어 포인터 (Instruction Pointer, IP)**라고도 불린다.
- **명령어 레지스터 (Instruction Register, IR)**
  - 메모리에서 방금 읽어온, 즉 현재 해석할 명령어 자체를 저장하는 레지스터이다.
  - CPU는 IR에 저장된 명령어의 연산 코드(opcode)와 오퍼랜드(operand)를 분석하여 실제 작업을 수행한다.
- **스택 포인터 (Stack Pointer, SP)**
  - 메모리의 스택(Stack) 영역의 가장 마지막에 저장된 데이터 위치(주소)를 가리키는 레지스터이다. 
  - 스택은 함수 호출 시 지역 변수나 복귀 주소 등을 임시로 저장하는 데 사용되며, 스택 포인터는 이 스택 영역을 관리하는 데 필수적이다.

### 범용 레지스터

- 이름 그대로 다양한 용도로 사용될 수 있는 레지스터이다.
- 데이터(숫자, 문자 등)나 메모리 주소를 임시로 저장하는 데 자유롭게 활용된다.
- 프로그래머나 컴파일러는 연산 중간 결과나 필요한 값을 빠르게 접근하기 위해 이 레지스터들을 사용한다.

### 플래그 레지스터

CPU의 현재 상태나 가장 최근에 수행된 연산 결과에 대한 추가적인 정보를 담고 있는 레지스터이다.

이 레지스터의 각 비트(bit)는 특정 상태를 나타내는 플래그(Flag) 역할을 한다다. 

주요 플래그는 다음과 같다.

- **부호 플래그 (Sign Flag, SF)**: 연산 결과가 음수이면 1, 양수(또는 0)이면 0으로 설정된다.
- **제로 플래그 (Zero Flag, ZF)**: 연산 결과가 0이면 1, 0이 아니면 0으로 설정된다.
- **캐리 플래그 (Carry Flag, CF)**: 부호 없는 정수 연산에서 자리 올림(carry)이나 빌림(borrow)이 발생하면 1로 설정된다. 주로 큰 수의 덧셈/뺄셈에 사용된다.
- **오버플로우 플래그 (Overflow Flag, OF)**: 부호 있는 정수 연산 결과가 표현 가능한 범위를 벗어나는 오버플로우가 발생하면 1로 설정된다.
- **인터럽트 플래그 (Interrupt Enable Flag, IF)**: CPU가 외부 인터럽트 요청을 받아들일지 여부를 제어한다. 이 플래그가 1이면 인터럽트를 허용하고, 0이면 (일부 특수 인터럽트 제외) 무시한다.
- **슈퍼바이저 플래그 (Supervisor Flag / Mode Flag)**: CPU가 운영체제 커널 코드(슈퍼바이저 모드)를 실행 중인지, 아니면 일반 사용자 프로그램(사용자 모드)을 실행 중인지 나타낸다. 시스템 보안과 관련된다.

## 인터럽트

인터럽트란 현재 실행 중인 CPU 작업을 방해하는 신호이다.

CPU는 프로그램을 순차적으로 실행하지만, 외부 장치나 내부 오류 등 예상치 못한 상황이 발생하면 하던 일을 잠시 멈추고 해당 상황을 먼저 처리해야 할 필요가 있다.

이러한 인터럽트 메커니즘은 CPU가 입출력 장치의 완료를 계속 기다리지 않고 다른 작업을 하다가, 장치로부터 알림을 받아 해당 작업을 처리하게 함으로써 시스템 효율성을 높이는 데 중요한 역할을 한다. 

즉, 효율적으로 명령어를 처리하기 위함이라고 볼 수 있다.

### 인터럽트 종류

인터럽트는 발생 원인에 따라 다음과 같이 분류된다.

- **동기 인터럽트 (Synchronous Interrupt) / 예외 (Exception)**
  - CPU가 명령어를 실행하는 도중에 발생하는 예외적인 상황으로 인해 발생합니다. 예를 들어, 0으로 나누기, 허용되지 않은 메모리 영역 접근 시도 등이 예외에 해당한다.
  - 현재 실행 중인 명령어와 직접적으로 관련되어 발생하므로 '동기적'이라고 한다.
- **비동기 인터럽트 (Asynchronous Interrupt) / 하드웨어 인터럽트 (Hardware Interrupt)**
  - 주로 입출력장치에 의해 발생하는 인터럽트이다.
  - 키보드 입력, 마우스 움직임, 디스크 읽기 완료 등 CPU 외부의 하드웨어적인 요인으로 발생한다.
  - 현재 실행 중인 명령어와는 관계없이 비동기적으로 발생한다.
  - 하드웨어 인터럽트는 다시 막을 수 있는 인터럽트 (Maskable Interrupt)와 막을 수 없는 인터럽트 (Non-Maskable Interrupt, NMI)로 나뉜다.
  - 막을 수 있는 인터럽트는 CPU의 인터럽트 플래그 (Interrupt Flag, IF) 설정을 통해 일시적으로 무시할 수 있지만, 정전이나 하드웨어 고장 등 심각한 상황을 알리는 NMI는 무시할 수 없다.
- **소프트웨어 인터럽트 (Software Interrupt)**
  - 프로그램 코드 내에서 특별한 명령어(예: 시스템 콜)를 실행하여 의도적으로 인터럽트를 발생시키는 경우이다.
  - 운영체제의 서비스를 요청할 때 주로 사용된다.

### CPU의 하드웨어 인터럽트 처리 순서

CPU가 (막을 수 있는) 하드웨어 인터럽트를 처리하는 과정은 일반적으로 다음과 같은 순서를 따른다.

- **인터럽트 요청 신호 감지**
  - 입출력 장치가 CPU에게 작업을 요청하는 인터럽트 요청 신호(Interrupt Request, IRQ)를 보낸다.
- **인터럽트 확인 및 허용 여부 판단**
  - CPU는 현재 명령어 실행을 마친 후 (보통 인터럽트를 처리하는 인터럽트 사이클 단계에서) 인터럽트 요청이 있는지 확인한다. 
  - 그리고 플래그 레지스터의 인터럽트 플래그(IF)를 확인하여 해당 인터럽트를 받아들일지 결정한다. (NMI는 이 플래그와 상관없이 처리된다.)
- **현재 상태 백업**
  - 인터럽트를 처리하기로 결정하면, CPU는 현재 실행 중이던 프로그램으로 안전하게 돌아오기 위해 필요한 정보들, 즉 현재 프로그램을 재개하기 위해 필요한 모든 내용(주로 프로그램 카운터(PC) 값과 주요 레지스터 값 등)을 백업한다. 
  - 이 정보들은 일반적으로 메모리의 특정 영역인 스택(Stack)에 저장된다.
- **인터럽트 벡터 확인 및 ISR 주소 획득**
  - CPU는 어떤 장치가 인터럽트를 요청했는지 식별하고, 해당 인터럽트 종류에 따라 처리해야 할 프로그램(ISR)의 시작 주소를 알아낸다. 
  - 이 정보는 인터럽트 벡터(Interrupt Vector)라는 테이블에 미리 정의되어 있다. 
  - 즉, 인터럽트 벡터를 참조하여 실행할 인터럽트 서비스 루틴의 시작 주소를 찾는다.
- **ISR(인터럽트 핸들러) 실행**
  - CPU는 인터럽트 벡터 테이블에서 얻은 시작 주소로 점프하여 인터럽트 서비스 루틴(Interrupt Service Routine, ISR) 또는 인터럽트 핸들러(Interrupt Handler)라고 불리는 프로그램을 실행한다. 
  - 이 루틴에는 어떤 인터럽트가 발생했을 때 해당 인터럽트를 어떻게 처리하고 작동해야 할지에 대한 정보(즉, 실제 처리 코드)가 들어있다.
- **상태 복구 및 원래 작업 복귀**
  - ISR 실행이 완료되면, CPU는 스택에 백업해 두었던 프로그램 카운터 값과 레지스터 값들을 다시 복원한다.
- **원래 작업 재개**
  - CPU는 인터럽트가 발생하기 직전에 실행하던 본래 수행하던 작업으로 다시 되돌아와 중단되었던 지점부터 실행을 이어간다.

### 예외 처리 방식 (동기 인터럽트)

동기 인터럽트(예외)가 발생했을 때의 처리 방식은 예외의 종류에 따라 다음과 같이 구분된다.

- **폴트 (Fault)**
  - 예외를 발생시킨 명령어가 실행되기 전에 감지된다.
  - 운영체제가 원인(예: 페이지 부재)을 해결한 후, 예외가 발생한 명령어부터 다시 실행한다.
  - 즉, 폴트가 발생한 그 명령어부터 재시작한다.

- **트랩 (Trap)**
  - 예외를 발생시킨 명령어가 실행된 후에 감지된다.
  - 주로 디버깅이나 시스템 콜과 같은 의도된 예외에 사용된다.
  - 복귀 시 예외가 발생한 명령어의 다음 명령어부터 실행을 계속한다.
  - 트랩이 발생한 명령어는 다시 실행하지 않고, 그 다음 명령어부터 실행한다.

- **중단 (Abort)**
  - 하드웨어 고장 등 매우 심각하고 복구가 불가능한 오류가 발생했을 때 사용된다.
  - 프로그램을 강제로 중단시킨다.

## CPU 성능 향상을 위한 설계

CPU의 성능을 높이기 위한 설계 방식은 다양하지만, 크게 클럭 속도 향상과 처리 단위 확장(멀티코어, 멀티스레딩)으로 나눌 수 있다.

### 클럭 속도 (Clock Speed)

- **클럭 (Clock)**
  - CPU 내부의 모든 구성 요소가 동작을 동기화하기 위해 사용하는 주기적인 전기 신호야. 마치 오케스트라의 지휘자처럼 CPU 각 부분이 정해진 박자에 맞춰 작동하도록 한다.
- **CPU 클럭 속도 (Clock Speed)**
  - 클럭 신호가 1초당 몇 번이나 반복되는지를 나타내는 수치이다.
  - 단위로는 헤르츠(Hz)를 쓰고, 보통 기가헤르츠(GHz, 1초에 10억 번) 단위를 쓴다.
  - 클럭 속도가 높을수록 CPU는 같은 시간 동안 더 많은 명령어를 처리할 수 있어서 기본적인 성능 지표가 된다다.
- **클럭 속도 향상의 한계**
  - 클럭 속도를 무작정 높이면 발열 문제랑 소비 전력 증가 문제가 생긴다.
  - 높은 클럭 속도는 더 많은 열을 발생시키고, 이걸 효과적으로 제어하기 어렵기 때문에 클럭 속도 향상만으로는 성능 개선에 한계가 있다.

### 멀티코어와 멀티스레드

클럭 속도 향상의 한계를 극복하고 성능을 높이기 위해 등장한 핵심 기술이 멀티코어와 멀티스레드다.

- **코어 (Core)**
  - 명령어를 실제로 처리하는 CPU의 핵심 연산 장치다. 과거의 CPU는 대부분 단일 코어였다.
- 멀티코어 CPU (Multi-core CPU) / 멀티코어 프로세서 (Multi-core Processor)
  - 하나의 CPU 칩 안에 여러 개의 코어를 집적한 것을 말한다. 2개의 코어가 있으면 듀얼 코어, 4개면 쿼드 코어 등으로 불린다.
  - 여러 개의 코어가 동시에 독립적인 작업을 처리할 수 있게 되어 CPU의 전반적인 처리 능력이 향상된다.
  - 이는 여러 프로그램을 동시에 실행하거나, 단일 프로그램 내에서도 병렬 처리가 가능한 작업을 나누어 수행할 때 성능 향상으로 이어진다.
- **스레드 (Thread)**
  - **소프트웨어 스레드 (Software Thread)**
    - 운영체제(OS) 수준에서 관리되는 실행 흐름의 단위다.
    - 하나의 프로세스(실행 중인 프로그램)는 여러 개의 스레드로 구성되어 동시에 여러 작업을 수행하는 것처럼 보일 수 있다.
  - **하드웨어 스레드 (Hardware Thread)**
    - 하나의 물리적인 코어가 동시에 처리할 수 있는 명령어 흐름의 단위다.
- **멀티스레드 프로세서 (Multithread Processor) / 멀티스레드 CPU (Multithread CPU)**
  - 하나의 물리적 코어가 여러 개의 하드웨어 스레드를 동시에 처리할 수 있도록 설계된 CPU다.
  - 이를 통해 코어의 유휴 시간을 줄이고 처리 효율을 높인다.
- **논리 프로세서 (Logical Processor)**
  - 운영체제 입장에서는 각 하드웨어 스레드를 독립적인 처리 단위로 인식하게 되는데, 이를 논리 프로세서라고 부른다.
  - 예시:
    - **1코어 1스레드 CPU**: 가장 기본적인 형태로, 하나의 코어가 한 번에 하나의 작업 흐름만 처리한다.
    - **2코어 4스레드 CPU**: 2개의 물리적 코어가 있고, 각 코어는 2개의 하드웨어 스레드를 동시에 처리할 수 있다. 따라서 운영체제는 총 4개의 논리 프로세서가 있는 것처럼 인식하고 작업을 할당한다.


### 병렬성(Parallelism)과 동시성(Concurrency)
- **병렬성 (Parallelism)**
  - 멀티코어 환경에서 실제로 여러 작업이 동시에 실행되는 것을 의미한다.
  - 물리적인 코어 수만큼의 작업이 진정한 의미에서 병렬적으로 처리될 수 있다.
- **동시성 (Concurrency)**
  - 단일 코어에서도 여러 작업을 짧은 시간 간격으로 번갈아 가며 처리하여 동시에 실행되는 것처럼 보이게 하는 것을 의미한다.
  - 멀티스레딩 기술은 동시성을 효율적으로 구현하고, 멀티코어 환경에서는 병렬성을 더욱 높이는 데 기여한다.


## 파이프라이닝을 통한 명령어 병렬 처리

CPU의 성능을 향상시키는 중요한 방법 중 하나는 명령어를 더 빠르게 처리하는 것이다. 

이를 위한 대표적인 명령어 병렬 처리 기법이 바로 명령어 파이프라이닝(Instruction Pipelining)이다.

### 명령어 파이프라이닝의 기본 원리

- 하나의 명령어를 처리하는 과정은 일반적으로 여러 단계로 나눌 수 있다.
- 예를 들어, 명령어를 메모리에서 가져오는 인출(Fetch) 단계, 명령어를 해석하는 해독(Decode) 단계, 실제 연산을 수행하는 실행(Execute) 단계, 그리고 결과를 레지스터나 메모리에 저장(Write-back/Store)하는 단계 등으로 구성된다.
- 명령어 파이프라이닝은 이 각각의 단계를 별도의 하드웨어(파이프라인 스테이지)가 처리하도록 하여, 여러 명령어가 동시에 다른 단계에서 처리될 수 있도록 하는 기술이다. 
- 마치 공장의 조립 라인처럼, 첫 번째 명령어가 실행 단계에 있을 때, 두 번째 명령어는 해독 단계에, 세 번째 명령어는 인출 단계에 있을 수 있다.
- 이를 통해 CPU는 한 클럭 사이클마다 하나의 명령어가 완료되는 것처럼 보여 전체적인 명령어 처리 속도를 크게 향상시킬 수 있다.

### 파이프라이닝과 CPU 아키텍처 (CISC vs RISC)

- **CISC (Complex Instruction Set Computer)**
  - 복잡하고 다양한 길이의 명령어를 가진다.
  - 명령어 길이가 가변적이고 실행 시간이 다르기 때문에 파이프라인 설계가 복잡해질 수 있다.
- **RISC (Reduced Instruction Set Computer)**
  - 단순하고 고정된 길이의 명령어를 사용한다.
  - 명령어 형식이 규칙적이어서 파이프라인 단계들을 균등하게 나누고 효율적으로 관리하기에 더 유리하다.
  - 따라서 RISC 아키텍처는 깊은 파이프라이닝 구현에 더 적합한 경향이 있다.

### 파이프라인 위험

파이프라이닝은 이론적으로 성능을 크게 향상시키지만, 실제로는 파이프라인의 흐름을 방해하는 여러 문제, 즉 파이프라인 위험(Pipeline Hazards)이 발생할 수 있다.

이 위험들은 파이프라인의 효율성을 떨어뜨린다. 주요 위험의 종류는 다음과 같다.

- **데이터 위험 (Data Hazard)**
  - 파이프라인 내의 어떤 명령어가 이전 명령어의 결과값이 나올 때까지 기다려야 하는 상황에서 발생한다. 
  - 이는 명령어 간의 데이터 의존성(Data Dependency) 때문에 발생한다. 
  - 예를 들어, 이전 덧셈 명령어의 결과값을 다음 명령어가 즉시 사용해야 하는데, 덧셈 결과가 아직 저장(Write-back) 단계까지 도달하지 못했을 경우 데이터 위험이 발생한다.
- **제어 위험 (Control Hazard)**
  - 분기(branch)나 점프(jump) 명령어와 같이 프로그램의 실행 흐름을 바꾸는 명령어 때문에 발생한다. 
  - 이러한 명령어들은 프로그램 카운터(PC)의 갑작스러운 변화를 유발하여, 파이프라인이 다음에 어떤 명령어를 인출해야 할지 미리 예측하기 어렵게 만든다. 
  - 잘못된 예측으로 불필요한 명령어를 파이프라인에 가져왔다면 파이프라인을 비우고 올바른 명령어를 다시 가져와야 하므로 성능 저하가 발생한다.
- **구조적 위험 (Structural Hazard)**
  - 파이프라인 내의 서로 다른 명령어가 동시에 동일한 CPU 내부 자원(예: 메모리 접근 유닛, 연산 장치 등)을 사용하려고 할 때 발생한다. 
  - 하드웨어 자원이 부족하여 명령어들이 동시에 해당 자원을 사용할 수 없을 때 파이프라인의 진행이 잠시 멈추게 된다.

# 3. 메모리

## RAM

### RAM의 기본 특성 및 접근 방식

- **저장 특성**
  - RAM은 주기억장치의 한 종류로, 대표적인 휘발성 저장장치(Volatile Storage)이다. 
  - 즉, 전원이 공급되는 동안에만 데이터를 저장하고, 전원이 차단되면 저장된 내용이 모두 사라진다. 
  - 이는 전원이 꺼져도 데이터가 유지되는 하드 디스크나 SSD와 같은 비휘발성 저장장치(Non-volatile Storage)와 대비되는 특징이다.
- **접근 방식**
  - RAM의 가장 중요한 특징 중 하나는 임의 접근(Random Access)이 가능하다는 것이다. 
  - 이는 저장된 데이터의 물리적인 위치(주소)와 관계없이 어떤 위치의 데이터든 거의 동일한 속도로 접근할 수 있음을 의미한다. 
  - 이는 테이프처럼 처음부터 순서대로 접근해야 하는 순차 접근(Sequential Access)이나, 디스크처럼 특정 트랙까지 이동한 후 데이터를 읽는 직접 접근(Direct Access) 방식과는 차이가 있다. 
  - RAM의 이러한 임의 접근 특성 덕분에 CPU는 필요한 데이터를 매우 빠르게 읽고 쓸 수 있다.

### RAM의 주요 종류: SRAM, DRAM

- **SRAM (Static RAM)**
  - '정적(Static)' RAM은 플립플롭(Flip-flop)이라는 회로를 사용하여 데이터를 저장합니다. 전원이 공급되는 한 데이터가 유지되며, 주기적인 재충전(Refresh)이 필요 없습니다.
  - 구조가 복잡하고 집적도가 낮아 가격이 비싸지만, 접근 속도가 매우 빠릅니다.
  - 주로 CPU 내부의 캐시 메모리(Cache Memory)와 같이 빠른 속도가 필수적인 곳에 사용됩니다.
- **DRAM (Dynamic RAM)**
  - '동적(Dynamic)' RAM은 축전기(Capacitor)에 전하를 충전하는 방식으로 데이터를 저장합니다. 축전기의 전하는 시간이 지나면 자연스럽게 방전되므로, 데이터 유지를 위해 주기적으로 재충전(Refresh) 해주어야 합니다.
  - 구조가 단순하여 집적도를 높이기 쉽고 가격이 저렴하여 대용량으로 만들기 유리합니다.
  - SRAM보다 속도는 느리지만, 가격 대비 용량이 크기 때문에 컴퓨터의 주기억장치(메인 메모리)로 널리 사용됩니다.

### DRAM의 발전: SDRAM과 DDR SDRAM

우리가 흔히 메인 메모리로 사용하는 DRAM은 지속적으로 성능이 개선되어 왔다.

- **SDRAM (Synchronous DRAM)**
  - '동기식(Synchronous)' DRAM은 CPU의 시스템 버스 클럭 신호와 동기화되어 작동한다. 
  - 이전의 비동기식 DRAM보다 데이터 전송 타이밍을 정확하게 제어할 수 있어 데이터 처리 효율과 속도가 향상되었다.
- **DDR SDRAM (Double Data Rate SDRAM)**
  - SDRAM을 더욱 발전시킨 형태로, '이중 데이터 전송률(Double Data Rate)'이라는 이름처럼 한 번의 클럭 신호에 두 번의 데이터를 전송할 수 있다. 
  - 즉, 클럭 신호의 상승 에지(Rising Edge)와 하강 에지(Falling Edge) 모두에서 데이터를 전송하여 SDRAM 대비 실질적인 데이터 처리량을 2배로 높였다.
  - DDR SDRAM 이후에도 DDR2, DDR3, DDR4, DDR5 등으로 기술이 계속 발전하며 데이터 전송 속도와 효율성이 꾸준히 향상되고 있다.

## 메모리에 바이트를 밀어넣는 순서 - 빅 엔디안과 리틀 엔디안

컴퓨터 메모리는 데이터를 바이트(Byte) 단위로 주소를 매겨 저장한다. 

그런데 정수나 부동 소수점 수와 같이 여러 바이트(예: 4바이트 정수)로 구성된 데이터를 메모리에 저장할 때, 이 바이트들을 어떤 순서로 배열할지에 대한 약속이 필요하다. 

이 바이트 배열 순서를 엔디안(Endianness)이라고 하며, 크게 두 가지 방식이 있다.

### 빅 엔디안 (Big Endian)

- 정의: 데이터의 가장 중요한 바이트, 즉 최상위 바이트(Most Significant Byte, MSB)를 메모리의 낮은 번지 주소에 저장하는 방식이다. 나머지 바이트들은 주소값이 증가하는 순서대로 저장된다.
- 특징: 사람이 숫자를 읽고 쓰는 방식과 유사하게, 가장 큰 단위(상위 바이트)부터 순서대로 저장한다. 즉, 낮은 번지의 주소에 상위 바이트부터 저장된다.
- 예시: 4바이트 정수 0x12345678 (여기서 12가 MSB, 78이 LSB)을 메모리 주소 100번지부터 저장한다고 가정하면 다음과 같다다.
  - 주소 100: 12 (MSB)
  - 주소 101: 34
  - 주소 102: 56
  - 주소 103: 78 (LSB)

### 리틀 엔디안 (Little Endian)

- 정의: 데이터의 가장 덜 중요한 바이트, 즉 최하위 바이트(Least Significant Byte, LSB)를 메모리의 낮은 번지 주소에 저장하는 방식이다. 나머지 바이트들은 주소값이 증가하는 순서대로 저장된다.
- 특징: 낮은 번지의 주소에 하위 바이트부터 저장된다.
- 예시: 동일한 4바이트 정수 0x12345678을 메모리 주소 100번지부터 저장한다고 가정하면 다음과 같다.
  - 주소 100: 78 (LSB)
  - 주소 101: 56
  - 주소 102: 34
  - 주소 103: 12 (MSB)

### 중요성

- 엔디안 방식은 CPU 아키텍처(예: Intel x86 계열은 주로 리틀 엔디안, PowerPC나 SPARC 등은 빅 엔디안)나 네트워크 프로토콜(네트워크 바이트 순서는 빅 엔디안)에 따라 다르다.
- 서로 다른 엔디안 시스템 간에 데이터를 교환할 때는 바이트 순서를 맞춰주는 변환 작업이 필요하며, 이를 고려하지 않으면 데이터를 잘못 해석하게 된다.

## 캐시 메모리

### 캐시 메모리의 개념 및 필요성

- **캐시 메모리(Cache Memory)**
  - CPU의 처리 속도와 주기억장치(RAM)의 접근 속도 차이를 완화하기 위해 사용되는 고속의 임시 저장 공간이다. 
  - CPU는 매우 빠르지만, 상대적으로 느린 RAM에 매번 접근하면 성능 저하가 발생한다. 
  - 캐시 메모리는 이 속도 차이를 메우는 역할을 한다.
- **SRAM 기반 저장장치**
  - 캐시 메모리는 매우 빠른 접근 속도가 요구되므로, 일반적으로 SRAM(Static RAM) 기반으로 만들어진다. 
  - SRAM은 DRAM보다 빠르지만 가격이 비싸고 집적도가 낮아 대용량으로 만들기 어렵다.
- **핵심 원리**
  - 자주 사용될 법한 데이터를 가까이 위치시킴으로써 성능 향상을 꾀한다는 것이 캐시의 기본 아이디어이다. 
  - 즉, CPU가 앞으로 사용할 법한 데이터나 명령어를 미리 RAM에서 가져와 캐시에 저장해 둔다.

### 캐시 계층 구조

캐시 메모리는 보통 CPU에 더 가깝고 빠르지만 용량이 작은 캐시부터, CPU에서 더 멀고 느리지만 용량이 큰 캐시까지 여러 단계의 계층 구조로 구성된다.
  
- **L1 캐시 (Level 1 Cache)**
  - CPU 코어 내부에 위치하며 가장 빠르고 용량이 작다.
- **L2 캐시 (Level 2 Cache)**
  - 보통 L1 캐시보다는 크고 느리며, CPU 코어 내부 또는 외부에 위치할 수 있다.
- **L3 캐시 (Level 3 Cache)**
  - 여러 CPU 코어가 공유하는 경우가 많으며, L2 캐시보다 크고 느립니다.
- **분리형 캐시 (Split Cache)**
  - 특히 L1 캐시는 명령어만 저장하는 L1i 캐시 (Instruction Cache)와 데이터만 저장하는 L1d 캐시 (Data Cache)로 분리되어 있는 경우가 많습니다. 이를 분리형 캐시라고 하며, 명령어 인출과 데이터 접근이 동시에 일어날 때의 충돌(구조적 위험)을 줄여줍니다.

### 캐시 동작 방식: 캐시 히트와 캐시 미스

- CPU가 데이터나 명령어를 요청할 때, 먼저 캐시 메모리를 확인한다.
  - **캐시 히트 (Cache Hit)**
    - CPU가 요청한 데이터가 캐시에 이미 존재하는 경우이다. 
    - CPU는 매우 빠르게 해당 데이터를 가져와 사용할 수 있다.
  - **캐시 미스 (Cache Miss)**
    - CPU가 요청한 데이터가 캐시에 존재하지 않는 경우이다. 
    - 이 경우, CPU는 어쩔 수 없이 느린 RAM(또는 하위 레벨 캐시)에 접근하여 데이터를 가져와야 하고, 동시에 해당 데이터를 캐시에도 적재한다.
- **캐시 적중률 (Cache Hit Rate)**
  - CPU의 요청 중 캐시 히트가 발생한 비율이다. 
  - 캐시 적중률이 높을수록 캐시 메모리가 효율적으로 동작하고 있음을 의미하며, 시스템 전체 성능 향상에 기여한다.
  - 캐시 적중률 = 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)

### 캐시 효율성의 근거: 참조 지역성의 원리

캐시 메모리가 높은 적중률을 보이며 효율적으로 동작할 수 있는 이유는 프로그램이 데이터에 접근하는 경향성, 즉 참조 지역성의 원리 때문이다.

- **시간 지역성 (Temporal Locality)**
  - 최근에 접근한 데이터는 가까운 미래에 다시 접근될 가능성이 높다는 원리이다. 
  - 예를 들어, 반복문에서 사용되는 루프 카운터 변수나 함수 내에서 자주 사용되는 지역 변수 등이 해당된다.
- **공간 지역성 (Spatial Locality)**
  - 특정 데이터에 접근했을 때, 그 주변의 데이터에도 곧 접근할 가능성이 높다는 원리이다. 
  - 예를 들어, 배열(Array)의 원소를 순차적으로 접근하거나, 프로그램 코드가 순서대로 실행되는 경우가 해당된다.

### 캐시 메모리의 쓰기 정책과 일관성

CPU가 데이터를 변경(쓰기)할 때, 캐시 메모리와 주기억장치(RAM)의 데이터를 어떻게 관리할지에 대한 정책이다.

- **즉시 쓰기 (Write-Through)**
  - 데이터를 캐시에 쓸 때마다 즉시 RAM에도 해당 내용을 쓴다. 
  - 구현은 단순하지만, 쓰기 작업 시마다 RAM 접근이 필요하여 속도가 느릴 수 있다.
- **지연 쓰기 (Write-Back)**
  - 데이터를 캐시에만 먼저 쓰고, 해당 캐시 블록이 교체될 때(다른 데이터로 덮어써질 때) 변경된 내용이 있는 경우에만 RAM에 쓴다. 
  - 쓰기 성능은 향상되지만, 캐시와 RAM 간의 데이터 불일치가 발생할 수 있어, 특히 멀티코어 환경에서는 캐시 일관성(Cache Coherency) 유지를 위한 추가적인 메커니즘이 필요하다.

# 4. 보조기억장치와 입출력 장치

컴퓨터 시스템은 CPU와 주기억장치(RAM) 외에도 데이터를 영구적으로 저장하고 외부와 소통하기 위한 다양한 장치들을 포함한다.

## 보조기억장치

주기억장치(RAM)는 휘발성이므로 전원이 꺼지면 데이터가 사라진다. 

따라서 데이터를 영구적으로 보관하기 위한 비휘발성 저장장치, 즉 보조기억장치가 필요하다.

대표적인 보조기억장치는 다음과 같다.

- **하드디스크 드라이브 (HDD - Hard Disk Drive)**
  - 자기 디스크를 회전시키며 데이터를 읽고 쓰는 전통적인 방식의 저장장치이다. 
  - 대용량 구현이 용이하고 가격이 저렴하지만, 물리적인 움직임 때문에 속도가 느리고 충격에 약하다.
- **플래시 메모리 기반 저장장치 (Flash Memory Based Storage)**
  - 전기적으로 데이터를 쓰고 지우는 반도체 기반의 저장장치이다. 
  - 플래시 메모리(Flash Memory)를 사용하며, 대표적으로 SSD(Solid State Drive), USB 메모리 등이 있다. 
  - HDD보다 속도가 훨씬 빠르고 충격에 강하며 소음이 없지만, 가격이 상대적으로 비싸다.

## RAID

여러 개의 보조기억장치(주로 HDD 또는 SSD)를 마치 하나의 보조기억장치처럼 사용하여 데이터 안정성이나 성능을 향상시키는 기술이다. 

RAID를 구성하는 방법에 따라 여러 RAID 레벨(RAID Level)이 정의되어 있다.

- **RAID 0 (스트라이핑 - Striping)**
  - 데이터를 스트라이프(Stripe)라는 단위로 나누어 여러 디스크에 분산 저장(스트라이핑)한다.
  - 장점: 여러 디스크에서 동시에 읽고 쓸 수 있어 성능이 향상된다.
  - 단점: 저장된 정보가 안전하지 않다는 점이 가장 큰 문제이다. 디스크 하나만 고장 나도 전체 데이터를 잃게 된다. 데이터 안정성은 전혀 고려되지 않는다.
- **RAID 1 (미러링 - Mirroring)**
  - 동일한 데이터를 여러 디스크에 중복 저장(미러링)한다.
  - 장점: 디스크 하나가 고장 나도 다른 디스크에 데이터가 그대로 있어 복구가 간단하고 안정성이 높다.
  - 단점: 전체 디스크 용량의 절반만 사용 가능한 용량이 되어 효율성이 떨어진다.
- **RAID 4**
  - 데이터는 스트라이핑하고, 오류 검출 및 복구를 위한 패리티(Parity) 정보를 계산하여 패리티 정보를 저장하는 디스크를 따로 둔다.
  - 단점: 패리티 디스크에 병목 현상이 발생할 수 있다.
- **RAID 5**
  - RAID 4와 유사하지만, 패리티 정보를 여러 디스크에 분산하여 저장한다. 
  - 패리티 디스크 병목 현상을 완화한다. 
  - 안정성과 성능, 용량 효율성을 절충한 방식이다.
- **RAID 6**
  - 서로 다른 패리티 2개를 계산하여 서로 다른 디스크에 분산 저장한다. 
  - 즉, 오류를 검출하고 복구할 수 있는 수단이 2개인 셈이다. 
  - 이를 통해 최대 2개의 디스크가 동시에 고장 나도 데이터를 복구할 수 있어 안정성이 매우 높다.
- **NESTED RAID (중첩 RAID)**
  - RAID 0, 1, 5, 6 등을 조합하여 구성하는 방식이다. 
  - 예를 들어 RAID 10(RAID 1+0)은 미러링된 디스크들을 다시 스트라이핑하여 안정성과 성능을 동시에 높인다.

## 입출력 기법

CPU와 메모리가 보조기억장치 및 키보드, 마우스, 모니터 등 다양한 입출력 장치와 데이터를 주고받는 방식이다.

- **장치 컨트롤러 (Device Controller) / 입출력 모듈**
  - 각 입출력 장치에는 하드웨어적인 인터페이스 역할을 하는 장치 컨트롤러가 있다. 
  - CPU와 장치 사이에서 제어 신호 및 데이터를 중개한다.
- **장치 드라이버 (Device Driver)**
  - 운영체제(OS)가 특정 장치 컨트롤러를 제어할 수 있도록 하는 소프트웨어이다. 
  - OS와 하드웨어 사이의 인터페이스 역할을 한다.
  
CPU가 입출력 작업을 처리하는 방식은 다음과 같이 발전해왔다.

- **프로그램 입출력 (Programmed I/O)**
  - CPU가 입출력 장치의 상태를 계속 확인(폴링)하고 데이터 전송을 직접 처리하는 방식이다.
  - CPU가 입출력 작업이 끝날 때까지 다른 일을 하지 못하고 기다려야 하므로 비효율적이다.
  - CPU는 입출력 명령어를 사용하여 장치를 제어한다.
- **인터럽트 기반 입출력 (Interrupt-driven I/O)**
  - CPU가 입출력 작업을 장치 컨트롤러에게 지시한 후 다른 작업을 하다가, 입출력 작업이 완료되면 장치 컨트롤러가 CPU에게 인터럽트 신호를 보낸다.
  - CPU는 하던 일을 잠시 멈추고 인터럽트를 처리하여 데이터 전송을 완료한다.
  - 프로그램 입출력보다 효율적이다.
  - **다중 인터럽트**
    - 여러 장치에서 동시에 인터럽트가 발생할 수 있다. 이때는 우선순위가 중요하다.
    - 우선순위가 더 높은 인터럽트가 발생하면 현재 처리 중인 인터럽트(만약 우선순위가 낮다면)를 잠시 멈추고 더 높은 우선순위의 인터럽트를 먼저 처리한다.
    - 우선순위가 같다면 순차적으로 처리한다.
    - NMI(Non-Maskable Interrupt)는 무시할 수 없는 최우선 순위 인터럽트이다.
  - **프로그래머블 인터럽트 컨트롤러 (PIC - Programmable Interrupt Controller)**
    - 여러 장치의 인터럽트 요청을 관리하고 우선순위를 판별하여 CPU에게 전달하는 역할을 하는 하드웨어 칩이다.
- **DMA 입출력 (Direct Memory Access I/O)**
  - CPU의 개입을 최소화하여 입출력 장치와 메모리가 직접 메모리 접근 가능한 입출력을 수행하는 방식이다.
  - **DMA 컨트롤러 (DMAC)**
    - CPU를 대신하여 입출력 장치와 메모리 사이의 데이터 전송을 제어하는 특수한 컨트롤러이다.
  - **DMA 입출력 과정**
    - CPU는 DMA 컨트롤러에게 입출력할 데이터의 메모리 주소, 전송할 데이터 양, 입출력 장치 정보 등을 알려주고 다른 작업을 수행한다.
    - DMA 컨트롤러는 CPU의 도움 없이 직접 메모리에 접근하여 데이터 전송을 완료하고, 작업이 끝나면 CPU에게 인터럽트를 통해 알린다.
    - CPU 부하를 크게 줄여 시스템 성능을 향상시킨다.

## 입출력 버스 (I/O Bus)

CPU, 메모리, 그리고 다양한 입출력 장치 컨트롤러들을 연결하여 데이터와 제어 신호를 주고받는 통로이다.

- **PCIe (Peripheral Component Interconnect Express)**
  - 현대 컴퓨터에서 널리 사용되는 고속 직렬 인터페이스 버스 표준이다. 
  - 그래픽 카드, SSD, 네트워크 카드 등 고성능 장치를 연결하는 데 주로 사용된다.
- **레인 (Lane)**
  - PCIe는 여러 개의 직렬 데이터 전송 통로인 레인을 묶어서 사용한다. 
  - 레인 수가 많을수록 (x1, x4, x8, x16 등) 더 높은 대역폭(데이터 전송 속도)을 제공한다.

